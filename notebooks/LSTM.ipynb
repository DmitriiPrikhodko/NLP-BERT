{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "561d8191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#### Word2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "####\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchutils as tu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"russian\"))\n",
    "\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy,\n",
    "    BinaryPrecision,\n",
    "    BinaryRecall,\n",
    "    BinaryF1Score,\n",
    ")\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "# from ..src.rnn_preprocessing_dima import (\n",
    "#     data_preprocessing,\n",
    "#     preprocess_single_string,\n",
    "#     padding,\n",
    "#     get_words_by_freq,\n",
    "# )\n",
    "\n",
    "# from ..src.fit_model import fit_model, fit_with_mlflow, plot_history, binary_metrics\n",
    "\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b14b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "from tqdm.auto import tqdm\n",
    "import mlflow\n",
    "from time import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import sklearn\n",
    "import string\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291b6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# GENERATOR = (\n",
    "#     torch.Generator(device=DEVICE) if torch.cuda.is_available() else torch.Generator()\n",
    "# )\n",
    "GENERATOR = torch.Generator()\n",
    "\n",
    "use_mlflow = True\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "CURR_DIR = os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07988b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b97a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import mlflow\n",
    "from time import time\n",
    "import os\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy,\n",
    "    BinaryPrecision,\n",
    "    BinaryRecall,\n",
    "    BinaryF1Score,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def binary_metrics(outputs, labels, device):\n",
    "    acc = BinaryAccuracy().to(device)\n",
    "    prec = BinaryPrecision().to(device)\n",
    "    rec = BinaryRecall().to(device)\n",
    "    f1 = BinaryF1Score().to(device)\n",
    "\n",
    "    preds = outputs.squeeze().float()\n",
    "    labels = labels.squeeze().float()\n",
    "    return (\n",
    "        acc(preds, labels).item(),\n",
    "        prec(preds, labels).item(),\n",
    "        rec(preds, labels).item(),\n",
    "        f1(preds, labels).item(),\n",
    "    )\n",
    "\n",
    "\n",
    "def fit_model(\n",
    "    epochs: int,\n",
    "    model: nn.Module,\n",
    "    model_name: str,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    use_mlflow=False,\n",
    "):\n",
    "\n",
    "    log = dict()\n",
    "    log[\"train_loss\"] = []\n",
    "    log[\"valid_loss\"] = []\n",
    "    log[\"train_accuracy\"] = []\n",
    "    log[\"valid_accuracy\"] = []\n",
    "    log[\"train_precision\"] = []\n",
    "    log[\"valid_precision\"] = []\n",
    "    log[\"train_recall\"] = []\n",
    "    log[\"valid_recall\"] = []\n",
    "    log[\"train_f1\"] = []\n",
    "    log[\"valid_f1\"] = []\n",
    "\n",
    "    time_start = time()\n",
    "\n",
    "    start_epoch = len(log[\"train_loss\"])\n",
    "\n",
    "    ### Создаем папку для записи весов\n",
    "    # -----------------------------------------------------------------\n",
    "    # Создаём корневую папку weights, если её нет\n",
    "    folder_path = f\"weights/\"\n",
    "    model_folder_path = os.path.join(folder_path, f\"{model_name}\")\n",
    "\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "\n",
    "    # Список номеров run_*\n",
    "    run_nums = []\n",
    "\n",
    "    # Ищем все подпапки с именем run_число\n",
    "    for item_name in os.listdir(model_folder_path):\n",
    "        full_path = os.path.join(model_folder_path, item_name)\n",
    "        if os.path.isdir(full_path):\n",
    "            match = re.search(r\"run_(\\d+)\", item_name)\n",
    "            if match:\n",
    "                run_nums.append(int(match.group(1)))\n",
    "\n",
    "    # Определяем следующий номер\n",
    "    run = max(run_nums) + 1 if run_nums else 1\n",
    "\n",
    "    # Создаём новую папку\n",
    "    new_folder = os.path.join(model_folder_path, f\"run_{run}\")\n",
    "    os.makedirs(new_folder, exist_ok=True)\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    ### Цикл обучения\n",
    "    # -----------------------------------------------------------------\n",
    "    for epoch in range(start_epoch + 1, start_epoch + epochs + 1):\n",
    "\n",
    "        curr_run_path = os.path.join(folder_path, model_name, f\"run_{run}\")\n",
    "\n",
    "        epoch_time_start = time()\n",
    "\n",
    "        print(f'{\"-\"*13} Epoch {epoch} {\"-\"*13}')\n",
    "\n",
    "        ### Обучение\n",
    "\n",
    "        batch_acc = []\n",
    "        batch_prec = []\n",
    "        batch_recall = []\n",
    "        batch_loss = []\n",
    "        batch_f1 = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # Прогресс бар\n",
    "\n",
    "        train_pbar = tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=True\n",
    "        )\n",
    "\n",
    "        for inputs, labels in train_pbar:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Функции потерь\n",
    "\n",
    "            outputs, _ = model(inputs)\n",
    "            # outputs = model(inputs).squeeze()\n",
    "\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            # Метрики\n",
    "            acc, prec, rec, f1 = binary_metrics(outputs, labels, device=device)\n",
    "\n",
    "            batch_acc.append(acc)\n",
    "            batch_prec.append(prec)\n",
    "            batch_recall.append(rec)\n",
    "            batch_f1.append(f1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_pbar.set_postfix(\n",
    "            {\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1-score\": f1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        log[\"train_loss\"].append(np.mean(batch_loss))\n",
    "        log[\"train_accuracy\"].append(np.mean(batch_acc))\n",
    "        log[\"train_precision\"].append(np.mean(batch_prec))\n",
    "        log[\"train_recall\"].append(np.mean(batch_recall))\n",
    "        log[\"train_f1\"].append(np.mean(batch_f1))\n",
    "\n",
    "        ### Валидация\n",
    "\n",
    "        batch_acc = []\n",
    "        batch_prec = []\n",
    "        batch_recall = []\n",
    "        batch_loss = []\n",
    "        batch_f1 = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        valid_pbar = tqdm(\n",
    "            valid_loader, desc=f\"Epoch {epoch}/{epochs} [Test]\", leave=True\n",
    "        )\n",
    "        for inputs, labels in valid_pbar:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs, _ = model(inputs)\n",
    "                # outputs = model(inputs).squeeze()\n",
    "\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            # Метрики\n",
    "            acc, prec, rec, f1 = binary_metrics(outputs, labels, device=device)\n",
    "\n",
    "            batch_acc.append(acc)\n",
    "            batch_prec.append(prec)\n",
    "            batch_recall.append(rec)\n",
    "            batch_f1.append(f1)\n",
    "\n",
    "        valid_pbar.set_postfix(\n",
    "            {\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1-score\": f1,\n",
    "            }\n",
    "        )\n",
    "        ### Метрики и логирование\n",
    "\n",
    "        log[\"valid_loss\"].append(np.mean(batch_loss))\n",
    "        log[\"valid_accuracy\"].append(np.mean(batch_acc))\n",
    "        log[\"valid_precision\"].append(np.mean(batch_prec))\n",
    "        log[\"valid_recall\"].append(np.mean(batch_recall))\n",
    "        log[\"valid_f1\"].append(np.mean(batch_f1))\n",
    "\n",
    "        # [MLflow] Логируем метрики\n",
    "        if use_mlflow:\n",
    "            # epoch – номер шага (можно указывать step=epoch)\n",
    "            for c in log.keys():\n",
    "                mlflow.log_metric(c, log[c][-1], step=epoch)\n",
    "\n",
    "        epoch_time = time() - epoch_time_start\n",
    "\n",
    "        ### Выводим результаты эпохи\n",
    "        # Train stage\n",
    "        print(\n",
    "            f\"Train stage: \"\n",
    "            f\"loss: {log['train_loss'][-1]:>6.3f}  \"\n",
    "            f\"Accuracy: {log['train_accuracy'][-1]:>6.3f}  \"\n",
    "            f\"Precision: {log['train_precision'][-1]:>6.3f}  \"\n",
    "            f\"Recall: {log['train_recall'][-1]:>6.3f}  \"\n",
    "            f\"F1-score: {log['train_f1'][-1]:>6.3f}  \"\n",
    "        )\n",
    "\n",
    "        # Valid stage\n",
    "        print(\n",
    "            f\"Valid stage: \"\n",
    "            f\"loss: {log['valid_loss'][-1]:>6.3f}  \"\n",
    "            f\"Accuracy: {log['valid_accuracy'][-1]:>6.3f}  \"\n",
    "            f\"Precision: {log['valid_precision'][-1]:>6.3f}  \"\n",
    "            f\"Recall: {log['valid_recall'][-1]:>6.3f}  \"\n",
    "            f\"F1-score: {log['valid_f1'][-1]:>6.3f}  \"\n",
    "        )\n",
    "        print(f\"Time: {epoch_time}\")\n",
    "\n",
    "        print(f'{\"-\"*35}\\n')\n",
    "        torch.save(\n",
    "            model.state_dict(), os.path.join(curr_run_path, f\"weight_epoch_{epoch}.pth\")\n",
    "        )\n",
    "\n",
    "    total_training_time = time() - time_start\n",
    "    print(f\"Total time = {total_training_time:>5.1f} сек\")\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    return log, total_training_time, run\n",
    "\n",
    "\n",
    "def fit_with_mlflow(\n",
    "    model,\n",
    "    model_name,\n",
    "    epochs,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    batch_size,\n",
    "    lr,\n",
    "):\n",
    "    mlflow.set_experiment(\n",
    "        f\"{model_name} experiment\"\n",
    "    )  # установить (или создать) эксперимент\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_BS = {batch_size}_lr_{lr}\"):\n",
    "        # Логируем гиперпараметры из config\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"device\", device)\n",
    "        mlflow.log_param(\"optimizer\", optimizer)\n",
    "        mlflow.log_param(\"criterion\", criterion)\n",
    "\n",
    "        # mlflow.pytorch.autolog(\n",
    "        #     checkpoint=True,\n",
    "        #     checkpoint_save_best_only=False,\n",
    "        #     checkpoint_save_weights_only=False,\n",
    "        #     checkpoint_save_freq=\"epoch\",\n",
    "        # )\n",
    "        # mlflow.log_param(\"augmentation\", (\"Yes\" if augmentation else \"No\"))\n",
    "        print(\"начало обучения...\")\n",
    "        # Запускаем обучение\n",
    "        logs, tot_time, run = fit_model(\n",
    "            model=model,\n",
    "            model_name=model_name,\n",
    "            epochs=epochs,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            train_loader=train_loader,\n",
    "            valid_loader=valid_loader,\n",
    "            device=device,\n",
    "            use_mlflow=True,\n",
    "        )\n",
    "        mlflow.log_param(\"Total time\", tot_time)\n",
    "\n",
    "        # Сохраняем модель в MLflow (опционально)\n",
    "        # mlflow.pytorch.log_model(base_cnn, \"model\")\n",
    "\n",
    "    # После выхода из `with` Run автоматически завершается\n",
    "    return logs, tot_time, run\n",
    "\n",
    "\n",
    "def plot_history(history, grid=True, suptitle=\"model 1\"):\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(16, 20))\n",
    "    fig.suptitle(suptitle, fontsize=24, fontweight=\"bold\", y=0.85)\n",
    "    ax[0][0].plot(history[\"train_loss\"], label=\"train loss\")\n",
    "    ax[0][0].plot(history[\"valid_loss\"], label=\"valid loss\")\n",
    "    ax[0][0].set_title(f'Loss on epoch {len(history[\"train_loss\"])}', fontsize=16)\n",
    "    ax[0][0].grid(grid)\n",
    "    ax[0][0].set_ylim((0, max(history[\"train_loss\"] + history[\"valid_loss\"]) + 0.1))\n",
    "    ax[0][0].legend(fontsize=14)\n",
    "    ax[0][0].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[0][0].set_ylabel(\"Loss\", fontsize=14)\n",
    "\n",
    "    ax[0][1].plot(history[\"train_accuracy\"], label=\"train accuracy\")\n",
    "    ax[0][1].plot(history[\"valid_accuracy\"], label=\"valid accuracy\")\n",
    "    ax[0][1].set_title(\n",
    "        f'Accuracy on epoch {len(history[\"train_loss\"])}',\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax[0][1].grid(grid)\n",
    "    # ax[0][1].set_ylim((min(history[\"train_accuracy\"]) - 0.05, 1))\n",
    "    ax[0][1].set_ylim(0.5, 1)\n",
    "    ax[0][1].legend(fontsize=14)\n",
    "    ax[0][1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[0][1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "\n",
    "    ax[1][0].plot(history[\"train_precision\"], label=\"train precision\")\n",
    "    ax[1][0].plot(history[\"valid_precision\"], label=\"valid precision\")\n",
    "    ax[1][0].set_title(\n",
    "        f'Precision on epoch {len(history[\"train_loss\"])}',\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax[1][0].grid(grid)\n",
    "    ax[1][0].set_ylim(0.5, 1)\n",
    "    # ax[1][0].set_ylim(min(history[\"train_precision\"]) - 0.05, 1)\n",
    "    ax[1][0].legend(fontsize=14)\n",
    "    ax[1][0].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[1][0].set_ylabel(\"Precision\", fontsize=14)\n",
    "\n",
    "    ax[1][1].plot(history[\"train_recall\"], label=\"train recall\")\n",
    "    ax[1][1].plot(history[\"valid_recall\"], label=\"valid recall\")\n",
    "    ax[1][1].set_title(\n",
    "        f'Recal on epoch {len(history[\"train_loss\"])}', fontsize=16, fontweight=\"bold\"\n",
    "    )\n",
    "    ax[1][1].grid(grid)\n",
    "    ax[1][1].set_ylim(0.5, 1)\n",
    "    # ax[1][1].set_ylim((min(history[\"train_recall\"]) - 0.05, 1))\n",
    "    ax[1][1].legend(fontsize=14)\n",
    "    ax[1][1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[1][1].set_ylabel(\"Recal\", fontsize=14)\n",
    "\n",
    "    ax[2][0].plot(history[\"train_f1\"], label=\"train f1\")\n",
    "    ax[2][0].plot(history[\"valid_f1\"], label=\"valid f1\")\n",
    "    ax[2][0].set_title(\n",
    "        f'F1-score on epoch {len(history[\"train_loss\"])}',\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax[2][0].grid(grid)\n",
    "    ax[2][0].set_ylim(0.5, 1)\n",
    "    # ax[2][0].set_ylim((min(history[\"train_f1\"]) - 0.05, 1))\n",
    "    ax[2][0].legend(fontsize=14)\n",
    "    ax[2][0].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[2][0].set_ylabel(\"F1\", fontsize=14)\n",
    "\n",
    "    ax[2][1].remove()\n",
    "    plt.subplots_adjust(top=0.8)\n",
    "    # plt.tight_layout(rect=[0, 0, 1, 0.8])\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a904579",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.difference_update({\"не\", \"нет\", \"без\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a07fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_stop_words = {morph.parse(word)[0].normal_form for word in stop_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a15e0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(text: str) -> str:\n",
    "    \"\"\"preprocessing string: lowercase, removing html-tags, punctuation,\n",
    "                            stopwords, digits\n",
    "\n",
    "    Args:\n",
    "        text (str): input string for preprocessing\n",
    "\n",
    "    Returns:\n",
    "        str: preprocessed string\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"<.*?>\", \"\", text)  # html tags\n",
    "    text = \"\".join(\n",
    "        [c for c in text if c not in string.punctuation]\n",
    "    )  # Remove punctuation\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    text = \" \".join([word for word in text.split() if not word.isdigit()])\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_words_by_freq(sorted_words: list[tuple[str, int]], n: int = 10) -> list:\n",
    "    return list(filter(lambda x: x[1] > n, sorted_words))\n",
    "\n",
    "\n",
    "def padding(review_int: list, seq_len: int) -> np.array:  # type: ignore\n",
    "    \"\"\"Make left-sided padding for input list of tokens\n",
    "\n",
    "    Args:\n",
    "        review_int (list): input list of tokens\n",
    "        seq_len (int): max length of sequence, it len(review_int[i]) > seq_len it will be trimmed, else it will be padded by zeros\n",
    "\n",
    "    Returns:\n",
    "        np.array: padded sequences\n",
    "    \"\"\"\n",
    "    features = np.zeros((len(review_int), seq_len), dtype=int)\n",
    "    for i, review in enumerate(review_int):\n",
    "        if len(review) <= seq_len:\n",
    "            zeros = list(np.zeros(seq_len - len(review)))\n",
    "            new = zeros + review\n",
    "        else:\n",
    "            new = review[:seq_len]\n",
    "        features[i, :] = np.array(new)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def preprocess_single_string(\n",
    "    input_string: str, seq_len: int, vocab_to_int: dict, verbose: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Function for all preprocessing steps on a single string\n",
    "\n",
    "    Args:\n",
    "        input_string (str): input single string for preprocessing\n",
    "        seq_len (int): max length of sequence, it len(review_int[i]) > seq_len it will be trimmed, else it will be padded by zeros\n",
    "        vocab_to_int (dict, optional): word corpus {'word' : int index}. Defaults to vocab_to_int.\n",
    "\n",
    "    Returns:\n",
    "        list: preprocessed string\n",
    "    \"\"\"\n",
    "\n",
    "    preprocessed_string = data_preprocessing(input_string)\n",
    "    result_list = []\n",
    "    for word in preprocessed_string.split():\n",
    "        try:\n",
    "            result_list.append(vocab_to_int[word])\n",
    "        except KeyError as e:\n",
    "            if verbose:\n",
    "                print(f\"{e}: not in dictionary!\")\n",
    "            pass\n",
    "    result_padded = padding([result_list], seq_len)[0]\n",
    "\n",
    "    return torch.tensor(result_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a166a5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70597, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Огромное спасибо за чудесное удаление двух зуб...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хочу выразить особую благодарность замечательн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Добрый вечер! Хотелось бы поблагодарить сотруд...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Женщины советского образца в регистратуре не и...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>У меня с детства очень плохие зубы (тонкая и х...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  labels\n",
       "0  Огромное спасибо за чудесное удаление двух зуб...       1\n",
       "1  Хочу выразить особую благодарность замечательн...       1\n",
       "2  Добрый вечер! Хотелось бы поблагодарить сотруд...       1\n",
       "3  Женщины советского образца в регистратуре не и...       0\n",
       "4  У меня с детства очень плохие зубы (тонкая и х...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\n",
    "    os.path.join(CURR_DIR, \"..\", \"data\", \"healthcare_facilities_reviews.jsonl\"),\n",
    "    lines=True,\n",
    ")\n",
    "labels = df[\"sentiment\"].copy().apply(lambda x: 1 if x == \"positive\" else 0)\n",
    "df[\"labels\"] = labels\n",
    "data = df.loc[:, [\"content\", \"labels\"]].copy()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b831917",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df[\"content\"].tolist()\n",
    "preprocessed = [data_preprocessing(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82f836ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Главный врач абсолютно некомпетентна! Зря занимает свою должность и просиживает свою юбку! Её развальная политика приносит свои плоды - низкий уровень медицинского обслуживания. Нарушается основное право гражданина РФ на бесплатную медицинскую помощь!\n"
     ]
    }
   ],
   "source": [
    "print(data[\"content\"][985])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e48f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word for text in preprocessed for word in text.split()]\n",
    "sorted_words = Counter(corpus).most_common()\n",
    "sorted_words = get_words_by_freq(sorted_words, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "848619b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {w: i + 1 for i, (w, c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9bdd288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 4, 712, 511, 259, 1089, 34, 423, 245, 736, 664, 477, 866, 1613, 712, 31, 1003, 243, 15, 104, 1987, 2, 223]\n",
      "огромное спасибо чудесное удаление двух зубов мудрости мгновение доктор матвеев профессионал большой буквы боялась страшно заняло реально секунд согласилась удаление сразу второго зуба без боли страха очень рекомендую\n"
     ]
    }
   ],
   "source": [
    "reviews_int = []\n",
    "for text in preprocessed:\n",
    "    r = [vocab_to_int[word] for word in text.split() if vocab_to_int.get(word)]\n",
    "    reviews_int.append(r)\n",
    "print([i for i in reviews_int[0]])\n",
    "print(preprocessed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cb9ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 70597\n",
      "Random review for word2vec: ['обращалась', 'клинику', 'острой', 'болью', 'ночи', 'несмотря', 'час', 'администратор', 'алексеевна', 'прошла', 'кабинет', 'мной', 'зашла', 'молодая', 'девушка', 'сначала', 'не', 'это', 'врач', 'поскольку', 'боль', 'очень', 'не', 'оказалось', 'повезло', 'настоящий', 'профессионал', 'точно', 'знает', 'делает', 'боль', 'рукой', 'лечение', 'идет', 'принимает', 'удобное', 'время', 'лечусь', 'другим', 'советую']\n"
     ]
    }
   ],
   "source": [
    "w2v_input = []\n",
    "for review in preprocessed:\n",
    "    cur_review = []\n",
    "    for word in review.split():\n",
    "        if vocab_to_int.get(word):\n",
    "            cur_review.append(word)\n",
    "    w2v_input.append(cur_review)\n",
    "print(f\"Total reviews: {len(w2v_input)}\")\n",
    "print(f\"Random review for word2vec: {w2v_input[np.random.randint(0, 50000)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6108cdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3159"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab_to_int) + 1  # размер словаря вместе с токеном padding\n",
    "EMBEDDING_DIM = 64  # embedding_dim\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f112953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 70597\n"
     ]
    }
   ],
   "source": [
    "# Обучим Word2Vec\n",
    "wv = Word2Vec(vector_size=EMBEDDING_DIM)  # размерность вектора для слова\n",
    "# Сначала word2vec составляет словарь\n",
    "wv.build_vocab(w2v_input)\n",
    "print(f\"Total reviews: {wv.corpus_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034912ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52531057, 57581740)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.train(corpus_iterable=w2v_input, total_examples=wv.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad57ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(os.path.join(os.curdir, \"weights/W2V_weights/\"))\n",
    "wv.save(os.path.join(os.curdir, \"weights/W2V_weights/W2V_model.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab8baccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем слой эмбеддинга\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "# Бежим по всем словам словаря: если слово есть в word2vec,\n",
    "# достаем его вектор; если слова нет, то распечатываем его и пропускаем\n",
    "for word, i in vocab_to_int.items():\n",
    "    try:\n",
    "        embedding_vector = wv.wv[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError as e:\n",
    "        pass\n",
    "        print(f\"{e}: word: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f2abbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words x EMEDDING_DIM: (3159, 64)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "print(f\"Number of words x EMEDDING_DIM: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28328aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = padding(review_int=reviews_int, seq_len=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15904e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    np.array(padded),\n",
    "    pd.get_dummies(df[\"sentiment\"], drop_first=True).values.astype(\"int\"),\n",
    "    test_size=0.15,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d03b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 32\n",
    "SEQ_LEN = 64\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1326349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    generator=GENERATOR,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    generator=GENERATOR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90955cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size: int = HIDDEN_SIZE) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_key = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_query = nn.Linear(hidden_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, lstm_outputs, final_hidden):\n",
    "        # print(f\"LSTM output shape: {lstm_outputs.shape}\")\n",
    "        # print(f\"Final_hidden shape: {final_hidden.shape}\")\n",
    "        keys = self.linear_key(lstm_outputs)  # (batch_size, seq_len, hidden_size)\n",
    "        # print(f\"After linear keys shape: {keys.shape}\")\n",
    "        query = self.linear_query(final_hidden)  # (batch_size, hidden_size)\n",
    "        query = query.unsqueeze(1)  # (batch_size, 1, hidden_size)\n",
    "        # print(f\"After linear query shape: {query.shape}\")\n",
    "        x = self.tanh(keys + query)  # (batch_size, seq_len, hidden_size)\n",
    "        # print(f\"After + X shape: {x.shape}\")\n",
    "        x = self.cls(x)  # (batch_size, seq_len, 1)\n",
    "        # print(f\"After cls x shape: {x.shape}\")\n",
    "        x = x.squeeze(-1)  # (batch_size, seq_len)\n",
    "        # print(f\"After squeeze x shape: {x.shape}\")\n",
    "        attention_weights = F.softmax(x, dim=-1)  # (batch_size, seq_len)\n",
    "        # print(f\"Attention weights shape: {attention_weights.shape}\")\n",
    "        attention_weights_bmm = attention_weights.unsqueeze(\n",
    "            1\n",
    "        )  # (batch_size, 1, seq_len)\n",
    "        # print(f\"Attention weights for bmm shape: {attention_weights_bmm.shape}\")\n",
    "\n",
    "        # bmm : (batch_size, 1, seq_len) * (batch_size, seq_len, hidden_size) = (batch_size, 1, hidden_size)\n",
    "        context = torch.bmm(attention_weights_bmm, keys)  # (batch_size, 1, hidden_size)\n",
    "        # print(f\"Context shape: {context.shape}\")\n",
    "        context = context.squeeze(1)\n",
    "        # print(f\"Context final shape: {context.shape}\")\n",
    "\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bd81f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    n_layers: int\n",
    "    embedding_size: int\n",
    "    hidden_size: int\n",
    "    vocab_size: int = VOCAB_SIZE\n",
    "    device: str = DEVICE\n",
    "    seq_len: int = SEQ_LEN\n",
    "    bidirectional: Union[bool, int] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa41ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config = Config(\n",
    "    n_layers=4,\n",
    "    embedding_size=64,\n",
    "    hidden_size=32,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    device=DEVICE,\n",
    "    seq_len=64,\n",
    "    bidirectional=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77d4eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBahdanauAttention(nn.Module):\n",
    "    def __init__(self, config=my_config) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # инициализируем конфиг\n",
    "        self.config = config\n",
    "        self.seq_len = self.config.seq_len\n",
    "        self.vocab_size = self.config.vocab_size\n",
    "        self.hidden_size = self.config.hidden_size\n",
    "        self.emb_size = self.config.embedding_size\n",
    "        self.n_layers = self.config.n_layers\n",
    "        self.device = self.config.device\n",
    "        self.bidirectional = bool(self.config.bidirectional)\n",
    "\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(self.emb_size, self.hidden_size, batch_first=True)\n",
    "        self.bidirect_factor = 2 if self.bidirectional == 1 else 1\n",
    "        self.attn = BahdanauAttention(self.hidden_size)\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, 128), nn.Dropout(), nn.Tanh(), nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def model_description(self):\n",
    "        direction = \"bidirect\" if self.bidirectional else \"onedirect\"\n",
    "        return f\"rnn_{direction}_{self.n_layers}\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x)\n",
    "        outputs, (h_n, _) = self.lstm(embeddings)\n",
    "        # att_hidden, att_weights = self.attn(outputs, h_n[-1].squeeze(0))\n",
    "        att_hidden, att_weights = self.attn(outputs, h_n[-1])\n",
    "        out = self.clf(att_hidden)\n",
    "        return out, att_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e73991e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMBahdanauAttention(config=my_config)\n",
    "model = model.to(my_config.device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "LR_BAN = 1e-4\n",
    "WEIGHT_DECAY_BAN = 3e-4\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=LR_BAN, weight_decay=WEIGHT_DECAY_BAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4169c4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 26 12:53:49 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080        Off |   00000000:01:00.0  On |                  N/A |\n",
      "| 53%   47C    P0            113W /  340W |    1273MiB /  10240MiB |     17%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2081      G   /usr/lib/xorg/Xorg                      311MiB |\n",
      "|    0   N/A  N/A            2311      G   /usr/bin/gnome-shell                     84MiB |\n",
      "|    0   N/A  N/A            2968      G   ...Mattermost/mattermost-desktop         37MiB |\n",
      "|    0   N/A  N/A            3224      G   /opt/zoom/zoom                           44MiB |\n",
      "|    0   N/A  N/A            3232      G   ...-0e3d-4499-9e55-751f7f155f73}          3MiB |\n",
      "|    0   N/A  N/A            4156      G   ...144 --variations-seed-version         81MiB |\n",
      "|    0   N/A  N/A           18809      G   /proc/self/exe                          199MiB |\n",
      "|    0   N/A  N/A           19459      C   ...ect/NLP-BERT/.venv/bin/python        320MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a834cc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начало обучения...\n",
      "------------- Epoch 1 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce661636acd34be7b574d05ee4a083f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4b1250fc8947b4b9e66ba8aa6538f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.379  Accuracy:  0.822  Precision:  0.824  Recall:  0.904  F1-score:  0.854  \n",
      "Valid stage: loss:  0.231  Accuracy:  0.914  Precision:  0.932  Recall:  0.920  F1-score:  0.925  \n",
      "Time: 9.281614542007446\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 2 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2121c1060984b3ab8314ca3333a00fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed13f01b96e4228a2ac0813931c095b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.214  Accuracy:  0.921  Precision:  0.940  Recall:  0.924  F1-score:  0.931  \n",
      "Valid stage: loss:  0.210  Accuracy:  0.925  Precision:  0.942  Recall:  0.928  F1-score:  0.934  \n",
      "Time: 9.374075889587402\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 3 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3876a9697674d1cada818cc78b0ba43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edafae1100694c6dad760ba250d34dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.199  Accuracy:  0.926  Precision:  0.944  Recall:  0.929  F1-score:  0.936  \n",
      "Valid stage: loss:  0.201  Accuracy:  0.927  Precision:  0.946  Recall:  0.927  F1-score:  0.935  \n",
      "Time: 9.068009376525879\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 4 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba25fda9a694ed6a8428c66cce67324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95cb2959c4d444da4d489e8fcf16883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.190  Accuracy:  0.928  Precision:  0.947  Recall:  0.931  F1-score:  0.938  \n",
      "Valid stage: loss:  0.194  Accuracy:  0.930  Precision:  0.945  Recall:  0.936  F1-score:  0.939  \n",
      "Time: 8.940185070037842\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 5 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a53b1c8db54fb48aa398c5f1e4ed55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5eb3ae7dff4047bd02d70a92a92987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.184  Accuracy:  0.931  Precision:  0.948  Recall:  0.933  F1-score:  0.940  \n",
      "Valid stage: loss:  0.191  Accuracy:  0.930  Precision:  0.942  Recall:  0.938  F1-score:  0.939  \n",
      "Time: 8.944113492965698\n",
      "-----------------------------------\n",
      "\n",
      "Total time =  45.6 сек\n",
      "🏃 View run LSTM+BahdanauAtt_BS = 64_lr_0.0001 at: http://localhost:5000/#/experiments/590357008120533451/runs/70a33dc53c7a48d486c3a9ecfae6fbfd\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/590357008120533451\n"
     ]
    }
   ],
   "source": [
    "logs, total_time, run = fit_with_mlflow(\n",
    "    model=model,\n",
    "    model_name=\"LSTM+BahdanauAtt\",\n",
    "    epochs=5,\n",
    "    criterion=criterion,\n",
    "    optimizer=optim,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    device=my_config.device,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR_BAN,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
