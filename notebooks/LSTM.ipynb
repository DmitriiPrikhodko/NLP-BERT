{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "561d8191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#### Word2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "####\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchutils as tu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"russian\"))\n",
    "\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy,\n",
    "    BinaryPrecision,\n",
    "    BinaryRecall,\n",
    "    BinaryF1Score,\n",
    ")\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "# from ..src.rnn_preprocessing_dima import (\n",
    "#     data_preprocessing,\n",
    "#     preprocess_single_string,\n",
    "#     padding,\n",
    "#     get_words_by_freq,\n",
    "# )\n",
    "\n",
    "# from ..src.fit_model import fit_model, fit_with_mlflow, plot_history, binary_metrics\n",
    "\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b14b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "from tqdm.auto import tqdm\n",
    "import mlflow\n",
    "from time import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import sklearn\n",
    "import string\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291b6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# GENERATOR = (\n",
    "#     torch.Generator(device=DEVICE) if torch.cuda.is_available() else torch.Generator()\n",
    "# )\n",
    "GENERATOR = torch.Generator()\n",
    "\n",
    "use_mlflow = True\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "CURR_DIR = os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07988b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b97a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import mlflow\n",
    "from time import time\n",
    "import os\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy,\n",
    "    BinaryPrecision,\n",
    "    BinaryRecall,\n",
    "    BinaryF1Score,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def binary_metrics(outputs, labels, device):\n",
    "    acc = BinaryAccuracy().to(device)\n",
    "    prec = BinaryPrecision().to(device)\n",
    "    rec = BinaryRecall().to(device)\n",
    "    f1 = BinaryF1Score().to(device)\n",
    "\n",
    "    preds = outputs.squeeze().float()\n",
    "    labels = labels.squeeze().float()\n",
    "    return (\n",
    "        acc(preds, labels).item(),\n",
    "        prec(preds, labels).item(),\n",
    "        rec(preds, labels).item(),\n",
    "        f1(preds, labels).item(),\n",
    "    )\n",
    "\n",
    "\n",
    "def fit_model(\n",
    "    epochs: int,\n",
    "    model: nn.Module,\n",
    "    model_name: str,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    use_mlflow=False,\n",
    "):\n",
    "\n",
    "    log = dict()\n",
    "    log[\"train_loss\"] = []\n",
    "    log[\"valid_loss\"] = []\n",
    "    log[\"train_accuracy\"] = []\n",
    "    log[\"valid_accuracy\"] = []\n",
    "    log[\"train_precision\"] = []\n",
    "    log[\"valid_precision\"] = []\n",
    "    log[\"train_recall\"] = []\n",
    "    log[\"valid_recall\"] = []\n",
    "    log[\"train_f1\"] = []\n",
    "    log[\"valid_f1\"] = []\n",
    "\n",
    "    time_start = time()\n",
    "\n",
    "    start_epoch = len(log[\"train_loss\"])\n",
    "\n",
    "    ### –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤–µ—Å–æ–≤\n",
    "    # -----------------------------------------------------------------\n",
    "    # –°–æ–∑–¥–∞—ë–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É weights, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\n",
    "    folder_path = f\"weights/\"\n",
    "    model_folder_path = os.path.join(folder_path, f\"{model_name}\")\n",
    "\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "\n",
    "    # –°–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ run_*\n",
    "    run_nums = []\n",
    "\n",
    "    # –ò—â–µ–º –≤—Å–µ –ø–æ–¥–ø–∞–ø–∫–∏ —Å –∏–º–µ–Ω–µ–º run_—á–∏—Å–ª–æ\n",
    "    for item_name in os.listdir(model_folder_path):\n",
    "        full_path = os.path.join(model_folder_path, item_name)\n",
    "        if os.path.isdir(full_path):\n",
    "            match = re.search(r\"run_(\\d+)\", item_name)\n",
    "            if match:\n",
    "                run_nums.append(int(match.group(1)))\n",
    "\n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–º–µ—Ä\n",
    "    run = max(run_nums) + 1 if run_nums else 1\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –ø–∞–ø–∫—É\n",
    "    new_folder = os.path.join(model_folder_path, f\"run_{run}\")\n",
    "    os.makedirs(new_folder, exist_ok=True)\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    ### –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\n",
    "    # -----------------------------------------------------------------\n",
    "    for epoch in range(start_epoch + 1, start_epoch + epochs + 1):\n",
    "\n",
    "        curr_run_path = os.path.join(folder_path, model_name, f\"run_{run}\")\n",
    "\n",
    "        epoch_time_start = time()\n",
    "\n",
    "        print(f'{\"-\"*13} Epoch {epoch} {\"-\"*13}')\n",
    "\n",
    "        ### –û–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "        batch_acc = []\n",
    "        batch_prec = []\n",
    "        batch_recall = []\n",
    "        batch_loss = []\n",
    "        batch_f1 = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä\n",
    "\n",
    "        train_pbar = tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=True\n",
    "        )\n",
    "\n",
    "        for inputs, labels in train_pbar:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "\n",
    "            outputs, _ = model(inputs)\n",
    "            # outputs = model(inputs).squeeze()\n",
    "\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "            acc, prec, rec, f1 = binary_metrics(outputs, labels, device=device)\n",
    "\n",
    "            batch_acc.append(acc)\n",
    "            batch_prec.append(prec)\n",
    "            batch_recall.append(rec)\n",
    "            batch_f1.append(f1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_pbar.set_postfix(\n",
    "            {\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1-score\": f1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        log[\"train_loss\"].append(np.mean(batch_loss))\n",
    "        log[\"train_accuracy\"].append(np.mean(batch_acc))\n",
    "        log[\"train_precision\"].append(np.mean(batch_prec))\n",
    "        log[\"train_recall\"].append(np.mean(batch_recall))\n",
    "        log[\"train_f1\"].append(np.mean(batch_f1))\n",
    "\n",
    "        ### –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "\n",
    "        batch_acc = []\n",
    "        batch_prec = []\n",
    "        batch_recall = []\n",
    "        batch_loss = []\n",
    "        batch_f1 = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        valid_pbar = tqdm(\n",
    "            valid_loader, desc=f\"Epoch {epoch}/{epochs} [Test]\", leave=True\n",
    "        )\n",
    "        for inputs, labels in valid_pbar:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs, _ = model(inputs)\n",
    "                # outputs = model(inputs).squeeze()\n",
    "\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "            acc, prec, rec, f1 = binary_metrics(outputs, labels, device=device)\n",
    "\n",
    "            batch_acc.append(acc)\n",
    "            batch_prec.append(prec)\n",
    "            batch_recall.append(rec)\n",
    "            batch_f1.append(f1)\n",
    "\n",
    "        valid_pbar.set_postfix(\n",
    "            {\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1-score\": f1,\n",
    "            }\n",
    "        )\n",
    "        ### –ú–µ—Ç—Ä–∏–∫–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "\n",
    "        log[\"valid_loss\"].append(np.mean(batch_loss))\n",
    "        log[\"valid_accuracy\"].append(np.mean(batch_acc))\n",
    "        log[\"valid_precision\"].append(np.mean(batch_prec))\n",
    "        log[\"valid_recall\"].append(np.mean(batch_recall))\n",
    "        log[\"valid_f1\"].append(np.mean(batch_f1))\n",
    "\n",
    "        # [MLflow] –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        if use_mlflow:\n",
    "            # epoch ‚Äì –Ω–æ–º–µ—Ä —à–∞–≥–∞ (–º–æ–∂–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å step=epoch)\n",
    "            for c in log.keys():\n",
    "                mlflow.log_metric(c, log[c][-1], step=epoch)\n",
    "\n",
    "        epoch_time = time() - epoch_time_start\n",
    "\n",
    "        ### –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏\n",
    "        # Train stage\n",
    "        print(\n",
    "            f\"Train stage: \"\n",
    "            f\"loss: {log['train_loss'][-1]:>6.3f}  \"\n",
    "            f\"Accuracy: {log['train_accuracy'][-1]:>6.3f}  \"\n",
    "            f\"Precision: {log['train_precision'][-1]:>6.3f}  \"\n",
    "            f\"Recall: {log['train_recall'][-1]:>6.3f}  \"\n",
    "            f\"F1-score: {log['train_f1'][-1]:>6.3f}  \"\n",
    "        )\n",
    "\n",
    "        # Valid stage\n",
    "        print(\n",
    "            f\"Valid stage: \"\n",
    "            f\"loss: {log['valid_loss'][-1]:>6.3f}  \"\n",
    "            f\"Accuracy: {log['valid_accuracy'][-1]:>6.3f}  \"\n",
    "            f\"Precision: {log['valid_precision'][-1]:>6.3f}  \"\n",
    "            f\"Recall: {log['valid_recall'][-1]:>6.3f}  \"\n",
    "            f\"F1-score: {log['valid_f1'][-1]:>6.3f}  \"\n",
    "        )\n",
    "        print(f\"Time: {epoch_time}\")\n",
    "\n",
    "        print(f'{\"-\"*35}\\n')\n",
    "        torch.save(\n",
    "            model.state_dict(), os.path.join(curr_run_path, f\"weight_epoch_{epoch}.pth\")\n",
    "        )\n",
    "\n",
    "    total_training_time = time() - time_start\n",
    "    print(f\"Total time = {total_training_time:>5.1f} —Å–µ–∫\")\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    return log, total_training_time, run\n",
    "\n",
    "\n",
    "def fit_with_mlflow(\n",
    "    model,\n",
    "    model_name,\n",
    "    epochs,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    batch_size,\n",
    "    lr,\n",
    "):\n",
    "    mlflow.set_experiment(\n",
    "        f\"{model_name} experiment\"\n",
    "    )  # —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å (–∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å) —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_BS = {batch_size}_lr_{lr}\"):\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"device\", device)\n",
    "        mlflow.log_param(\"optimizer\", optimizer)\n",
    "        mlflow.log_param(\"criterion\", criterion)\n",
    "\n",
    "        # mlflow.pytorch.autolog(\n",
    "        #     checkpoint=True,\n",
    "        #     checkpoint_save_best_only=False,\n",
    "        #     checkpoint_save_weights_only=False,\n",
    "        #     checkpoint_save_freq=\"epoch\",\n",
    "        # )\n",
    "        # mlflow.log_param(\"augmentation\", (\"Yes\" if augmentation else \"No\"))\n",
    "        print(\"–Ω–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...\")\n",
    "        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "        logs, tot_time, run = fit_model(\n",
    "            model=model,\n",
    "            model_name=model_name,\n",
    "            epochs=epochs,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            train_loader=train_loader,\n",
    "            valid_loader=valid_loader,\n",
    "            device=device,\n",
    "            use_mlflow=True,\n",
    "        )\n",
    "        mlflow.log_param(\"Total time\", tot_time)\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ MLflow (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "        # mlflow.pytorch.log_model(base_cnn, \"model\")\n",
    "\n",
    "    # –ü–æ—Å–ª–µ –≤—ã—Ö–æ–¥–∞ –∏–∑ `with` Run –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è\n",
    "    return logs, tot_time, run\n",
    "\n",
    "\n",
    "def plot_history(history, grid=True, suptitle=\"model 1\"):\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(16, 20))\n",
    "    fig.suptitle(suptitle, fontsize=24, fontweight=\"bold\", y=0.85)\n",
    "    ax[0][0].plot(history[\"train_loss\"], label=\"train loss\")\n",
    "    ax[0][0].plot(history[\"valid_loss\"], label=\"valid loss\")\n",
    "    ax[0][0].set_title(f'Loss on epoch {len(history[\"train_loss\"])}', fontsize=16)\n",
    "    ax[0][0].grid(grid)\n",
    "    ax[0][0].set_ylim((0, max(history[\"train_loss\"] + history[\"valid_loss\"]) + 0.1))\n",
    "    ax[0][0].legend(fontsize=14)\n",
    "    ax[0][0].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[0][0].set_ylabel(\"Loss\", fontsize=14)\n",
    "\n",
    "    ax[0][1].plot(history[\"train_accuracy\"], label=\"train accuracy\")\n",
    "    ax[0][1].plot(history[\"valid_accuracy\"], label=\"valid accuracy\")\n",
    "    ax[0][1].set_title(\n",
    "        f'Accuracy on epoch {len(history[\"train_loss\"])}',\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax[0][1].grid(grid)\n",
    "    # ax[0][1].set_ylim((min(history[\"train_accuracy\"]) - 0.05, 1))\n",
    "    ax[0][1].set_ylim(0.5, 1)\n",
    "    ax[0][1].legend(fontsize=14)\n",
    "    ax[0][1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[0][1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "\n",
    "    ax[1][0].plot(history[\"train_precision\"], label=\"train precision\")\n",
    "    ax[1][0].plot(history[\"valid_precision\"], label=\"valid precision\")\n",
    "    ax[1][0].set_title(\n",
    "        f'Precision on epoch {len(history[\"train_loss\"])}',\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax[1][0].grid(grid)\n",
    "    ax[1][0].set_ylim(0.5, 1)\n",
    "    # ax[1][0].set_ylim(min(history[\"train_precision\"]) - 0.05, 1)\n",
    "    ax[1][0].legend(fontsize=14)\n",
    "    ax[1][0].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[1][0].set_ylabel(\"Precision\", fontsize=14)\n",
    "\n",
    "    ax[1][1].plot(history[\"train_recall\"], label=\"train recall\")\n",
    "    ax[1][1].plot(history[\"valid_recall\"], label=\"valid recall\")\n",
    "    ax[1][1].set_title(\n",
    "        f'Recal on epoch {len(history[\"train_loss\"])}', fontsize=16, fontweight=\"bold\"\n",
    "    )\n",
    "    ax[1][1].grid(grid)\n",
    "    ax[1][1].set_ylim(0.5, 1)\n",
    "    # ax[1][1].set_ylim((min(history[\"train_recall\"]) - 0.05, 1))\n",
    "    ax[1][1].legend(fontsize=14)\n",
    "    ax[1][1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[1][1].set_ylabel(\"Recal\", fontsize=14)\n",
    "\n",
    "    ax[2][0].plot(history[\"train_f1\"], label=\"train f1\")\n",
    "    ax[2][0].plot(history[\"valid_f1\"], label=\"valid f1\")\n",
    "    ax[2][0].set_title(\n",
    "        f'F1-score on epoch {len(history[\"train_loss\"])}',\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax[2][0].grid(grid)\n",
    "    ax[2][0].set_ylim(0.5, 1)\n",
    "    # ax[2][0].set_ylim((min(history[\"train_f1\"]) - 0.05, 1))\n",
    "    ax[2][0].legend(fontsize=14)\n",
    "    ax[2][0].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    ax[2][0].set_ylabel(\"F1\", fontsize=14)\n",
    "\n",
    "    ax[2][1].remove()\n",
    "    plt.subplots_adjust(top=0.8)\n",
    "    # plt.tight_layout(rect=[0, 0, 1, 0.8])\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a904579",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.difference_update({\"–Ω–µ\", \"–Ω–µ—Ç\", \"–±–µ–∑\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a07fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_stop_words = {morph.parse(word)[0].normal_form for word in stop_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a15e0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(text: str) -> str:\n",
    "    \"\"\"preprocessing string: lowercase, removing html-tags, punctuation,\n",
    "                            stopwords, digits\n",
    "\n",
    "    Args:\n",
    "        text (str): input string for preprocessing\n",
    "\n",
    "    Returns:\n",
    "        str: preprocessed string\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"<.*?>\", \"\", text)  # html tags\n",
    "    text = \"\".join(\n",
    "        [c for c in text if c not in string.punctuation]\n",
    "    )  # Remove punctuation\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    text = \" \".join([word for word in text.split() if not word.isdigit()])\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_words_by_freq(sorted_words: list[tuple[str, int]], n: int = 10) -> list:\n",
    "    return list(filter(lambda x: x[1] > n, sorted_words))\n",
    "\n",
    "\n",
    "def padding(review_int: list, seq_len: int) -> np.array:  # type: ignore\n",
    "    \"\"\"Make left-sided padding for input list of tokens\n",
    "\n",
    "    Args:\n",
    "        review_int (list): input list of tokens\n",
    "        seq_len (int): max length of sequence, it len(review_int[i]) > seq_len it will be trimmed, else it will be padded by zeros\n",
    "\n",
    "    Returns:\n",
    "        np.array: padded sequences\n",
    "    \"\"\"\n",
    "    features = np.zeros((len(review_int), seq_len), dtype=int)\n",
    "    for i, review in enumerate(review_int):\n",
    "        if len(review) <= seq_len:\n",
    "            zeros = list(np.zeros(seq_len - len(review)))\n",
    "            new = zeros + review\n",
    "        else:\n",
    "            new = review[:seq_len]\n",
    "        features[i, :] = np.array(new)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def preprocess_single_string(\n",
    "    input_string: str, seq_len: int, vocab_to_int: dict, verbose: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Function for all preprocessing steps on a single string\n",
    "\n",
    "    Args:\n",
    "        input_string (str): input single string for preprocessing\n",
    "        seq_len (int): max length of sequence, it len(review_int[i]) > seq_len it will be trimmed, else it will be padded by zeros\n",
    "        vocab_to_int (dict, optional): word corpus {'word' : int index}. Defaults to vocab_to_int.\n",
    "\n",
    "    Returns:\n",
    "        list: preprocessed string\n",
    "    \"\"\"\n",
    "\n",
    "    preprocessed_string = data_preprocessing(input_string)\n",
    "    result_list = []\n",
    "    for word in preprocessed_string.split():\n",
    "        try:\n",
    "            result_list.append(vocab_to_int[word])\n",
    "        except KeyError as e:\n",
    "            if verbose:\n",
    "                print(f\"{e}: not in dictionary!\")\n",
    "            pass\n",
    "    result_padded = padding([result_list], seq_len)[0]\n",
    "\n",
    "    return torch.tensor(result_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a166a5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70597, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –∑–∞ —á—É–¥–µ—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥–≤—É—Ö –∑—É–±...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–•–æ—á—É –≤—ã—Ä–∞–∑–∏—Ç—å –æ—Å–æ–±—É—é –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä! –•–æ—Ç–µ–ª–æ—Å—å –±—ã –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å —Å–æ—Ç—Ä—É–¥...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ñ–µ–Ω—â–∏–Ω—ã —Å–æ–≤–µ—Ç—Å–∫–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞ –≤ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–µ –Ω–µ –∏...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–£ –º–µ–Ω—è —Å –¥–µ—Ç—Å—Ç–≤–∞ –æ—á–µ–Ω—å –ø–ª–æ—Ö–∏–µ –∑—É–±—ã (—Ç–æ–Ω–∫–∞—è –∏ —Ö...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  labels\n",
       "0  –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –∑–∞ —á—É–¥–µ—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥–≤—É—Ö –∑—É–±...       1\n",
       "1  –•–æ—á—É –≤—ã—Ä–∞–∑–∏—Ç—å –æ—Å–æ–±—É—é –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω...       1\n",
       "2  –î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä! –•–æ—Ç–µ–ª–æ—Å—å –±—ã –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å —Å–æ—Ç—Ä—É–¥...       1\n",
       "3  –ñ–µ–Ω—â–∏–Ω—ã —Å–æ–≤–µ—Ç—Å–∫–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞ –≤ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–µ –Ω–µ –∏...       0\n",
       "4  –£ –º–µ–Ω—è —Å –¥–µ—Ç—Å—Ç–≤–∞ –æ—á–µ–Ω—å –ø–ª–æ—Ö–∏–µ –∑—É–±—ã (—Ç–æ–Ω–∫–∞—è –∏ —Ö...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\n",
    "    os.path.join(CURR_DIR, \"..\", \"data\", \"healthcare_facilities_reviews.jsonl\"),\n",
    "    lines=True,\n",
    ")\n",
    "labels = df[\"sentiment\"].copy().apply(lambda x: 1 if x == \"positive\" else 0)\n",
    "df[\"labels\"] = labels\n",
    "data = df.loc[:, [\"content\", \"labels\"]].copy()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b831917",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df[\"content\"].tolist()\n",
    "preprocessed = [data_preprocessing(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82f836ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ì–ª–∞–≤–Ω—ã–π –≤—Ä–∞—á –∞–±—Å–æ–ª—é—Ç–Ω–æ –Ω–µ–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–∞! –ó—Ä—è –∑–∞–Ω–∏–º–∞–µ—Ç —Å–≤–æ—é –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∏ –ø—Ä–æ—Å–∏–∂–∏–≤–∞–µ—Ç —Å–≤–æ—é —é–±–∫—É! –ï—ë —Ä–∞–∑–≤–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –ø—Ä–∏–Ω–æ—Å–∏—Ç —Å–≤–æ–∏ –ø–ª–æ–¥—ã - –Ω–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è. –ù–∞—Ä—É—à–∞–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–∞–≤–æ –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞ –†–§ –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—É—é –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –ø–æ–º–æ—â—å!\n"
     ]
    }
   ],
   "source": [
    "print(data[\"content\"][985])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e48f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word for text in preprocessed for word in text.split()]\n",
    "sorted_words = Counter(corpus).most_common()\n",
    "sorted_words = get_words_by_freq(sorted_words, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "848619b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {w: i + 1 for i, (w, c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9bdd288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 4, 712, 511, 259, 1089, 34, 423, 245, 736, 664, 477, 866, 1613, 712, 31, 1003, 243, 15, 104, 1987, 2, 223]\n",
      "–æ–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ —á—É–¥–µ—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥–≤—É—Ö –∑—É–±–æ–≤ –º—É–¥—Ä–æ—Å—Ç–∏ –º–≥–Ω–æ–≤–µ–Ω–∏–µ –¥–æ–∫—Ç–æ—Ä –º–∞—Ç–≤–µ–µ–≤ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã –±–æ—è–ª–∞—Å—å —Å—Ç—Ä–∞—à–Ω–æ –∑–∞–Ω—è–ª–æ —Ä–µ–∞–ª—å–Ω–æ —Å–µ–∫—É–Ω–¥ —Å–æ–≥–ª–∞—Å–∏–ª–∞—Å—å —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ä–∞–∑—É –≤—Ç–æ—Ä–æ–≥–æ –∑—É–±–∞ –±–µ–∑ –±–æ–ª–∏ —Å—Ç—Ä–∞—Ö–∞ –æ—á–µ–Ω—å —Ä–µ–∫–æ–º–µ–Ω–¥—É—é\n"
     ]
    }
   ],
   "source": [
    "reviews_int = []\n",
    "for text in preprocessed:\n",
    "    r = [vocab_to_int[word] for word in text.split() if vocab_to_int.get(word)]\n",
    "    reviews_int.append(r)\n",
    "print([i for i in reviews_int[0]])\n",
    "print(preprocessed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cb9ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 70597\n",
      "Random review for word2vec: ['–æ–±—Ä–∞—â–∞–ª–∞—Å—å', '–∫–ª–∏–Ω–∏–∫—É', '–æ—Å—Ç—Ä–æ–π', '–±–æ–ª—å—é', '–Ω–æ—á–∏', '–Ω–µ—Å–º–æ—Ç—Ä—è', '—á–∞—Å', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä', '–∞–ª–µ–∫—Å–µ–µ–≤–Ω–∞', '–ø—Ä–æ—à–ª–∞', '–∫–∞–±–∏–Ω–µ—Ç', '–º–Ω–æ–π', '–∑–∞—à–ª–∞', '–º–æ–ª–æ–¥–∞—è', '–¥–µ–≤—É—à–∫–∞', '—Å–Ω–∞—á–∞–ª–∞', '–Ω–µ', '—ç—Ç–æ', '–≤—Ä–∞—á', '–ø–æ—Å–∫–æ–ª—å–∫—É', '–±–æ–ª—å', '–æ—á–µ–Ω—å', '–Ω–µ', '–æ–∫–∞–∑–∞–ª–æ—Å—å', '–ø–æ–≤–µ–∑–ª–æ', '–Ω–∞—Å—Ç–æ—è—â–∏–π', '–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª', '—Ç–æ—á–Ω–æ', '–∑–Ω–∞–µ—Ç', '–¥–µ–ª–∞–µ—Ç', '–±–æ–ª—å', '—Ä—É–∫–æ–π', '–ª–µ—á–µ–Ω–∏–µ', '–∏–¥–µ—Ç', '–ø—Ä–∏–Ω–∏–º–∞–µ—Ç', '—É–¥–æ–±–Ω–æ–µ', '–≤—Ä–µ–º—è', '–ª–µ—á—É—Å—å', '–¥—Ä—É–≥–∏–º', '—Å–æ–≤–µ—Ç—É—é']\n"
     ]
    }
   ],
   "source": [
    "w2v_input = []\n",
    "for review in preprocessed:\n",
    "    cur_review = []\n",
    "    for word in review.split():\n",
    "        if vocab_to_int.get(word):\n",
    "            cur_review.append(word)\n",
    "    w2v_input.append(cur_review)\n",
    "print(f\"Total reviews: {len(w2v_input)}\")\n",
    "print(f\"Random review for word2vec: {w2v_input[np.random.randint(0, 50000)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6108cdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3159"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab_to_int) + 1  # —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è –≤–º–µ—Å—Ç–µ —Å —Ç–æ–∫–µ–Ω–æ–º padding\n",
    "EMBEDDING_DIM = 64  # embedding_dim\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f112953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 70597\n"
     ]
    }
   ],
   "source": [
    "# –û–±—É—á–∏–º Word2Vec\n",
    "wv = Word2Vec(vector_size=EMBEDDING_DIM)  # —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Å–ª–æ–≤–∞\n",
    "# –°–Ω–∞—á–∞–ª–∞ word2vec —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å–ª–æ–≤–∞—Ä—å\n",
    "wv.build_vocab(w2v_input)\n",
    "print(f\"Total reviews: {wv.corpus_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034912ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52531057, 57581740)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.train(corpus_iterable=w2v_input, total_examples=wv.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad57ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(os.path.join(os.curdir, \"weights/W2V_weights/\"))\n",
    "wv.save(os.path.join(os.curdir, \"weights/W2V_weights/W2V_model.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab8baccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º —Å–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–∞\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "# –ë–µ–∂–∏–º –ø–æ –≤—Å–µ–º —Å–ª–æ–≤–∞–º —Å–ª–æ–≤–∞—Ä—è: –µ—Å–ª–∏ —Å–ª–æ–≤–æ –µ—Å—Ç—å –≤ word2vec,\n",
    "# –¥–æ—Å—Ç–∞–µ–º –µ–≥–æ –≤–µ–∫—Ç–æ—Ä; –µ—Å–ª–∏ —Å–ª–æ–≤–∞ –Ω–µ—Ç, —Ç–æ —Ä–∞—Å–ø–µ—á–∞—Ç—ã–≤–∞–µ–º –µ–≥–æ –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º\n",
    "for word, i in vocab_to_int.items():\n",
    "    try:\n",
    "        embedding_vector = wv.wv[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError as e:\n",
    "        pass\n",
    "        print(f\"{e}: word: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f2abbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words x EMEDDING_DIM: (3159, 64)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "print(f\"Number of words x EMEDDING_DIM: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28328aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = padding(review_int=reviews_int, seq_len=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15904e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    np.array(padded),\n",
    "    pd.get_dummies(df[\"sentiment\"], drop_first=True).values.astype(\"int\"),\n",
    "    test_size=0.15,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d03b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 32\n",
    "SEQ_LEN = 64\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1326349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    generator=GENERATOR,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    generator=GENERATOR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90955cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size: int = HIDDEN_SIZE) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_key = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_query = nn.Linear(hidden_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, lstm_outputs, final_hidden):\n",
    "        # print(f\"LSTM output shape: {lstm_outputs.shape}\")\n",
    "        # print(f\"Final_hidden shape: {final_hidden.shape}\")\n",
    "        keys = self.linear_key(lstm_outputs)  # (batch_size, seq_len, hidden_size)\n",
    "        # print(f\"After linear keys shape: {keys.shape}\")\n",
    "        query = self.linear_query(final_hidden)  # (batch_size, hidden_size)\n",
    "        query = query.unsqueeze(1)  # (batch_size, 1, hidden_size)\n",
    "        # print(f\"After linear query shape: {query.shape}\")\n",
    "        x = self.tanh(keys + query)  # (batch_size, seq_len, hidden_size)\n",
    "        # print(f\"After + X shape: {x.shape}\")\n",
    "        x = self.cls(x)  # (batch_size, seq_len, 1)\n",
    "        # print(f\"After cls x shape: {x.shape}\")\n",
    "        x = x.squeeze(-1)  # (batch_size, seq_len)\n",
    "        # print(f\"After squeeze x shape: {x.shape}\")\n",
    "        attention_weights = F.softmax(x, dim=-1)  # (batch_size, seq_len)\n",
    "        # print(f\"Attention weights shape: {attention_weights.shape}\")\n",
    "        attention_weights_bmm = attention_weights.unsqueeze(\n",
    "            1\n",
    "        )  # (batch_size, 1, seq_len)\n",
    "        # print(f\"Attention weights for bmm shape: {attention_weights_bmm.shape}\")\n",
    "\n",
    "        # bmm : (batch_size, 1, seq_len) * (batch_size, seq_len, hidden_size) = (batch_size, 1, hidden_size)\n",
    "        context = torch.bmm(attention_weights_bmm, keys)  # (batch_size, 1, hidden_size)\n",
    "        # print(f\"Context shape: {context.shape}\")\n",
    "        context = context.squeeze(1)\n",
    "        # print(f\"Context final shape: {context.shape}\")\n",
    "\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bd81f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    n_layers: int\n",
    "    embedding_size: int\n",
    "    hidden_size: int\n",
    "    vocab_size: int = VOCAB_SIZE\n",
    "    device: str = DEVICE\n",
    "    seq_len: int = SEQ_LEN\n",
    "    bidirectional: Union[bool, int] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa41ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config = Config(\n",
    "    n_layers=4,\n",
    "    embedding_size=64,\n",
    "    hidden_size=32,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    device=DEVICE,\n",
    "    seq_len=64,\n",
    "    bidirectional=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77d4eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBahdanauAttention(nn.Module):\n",
    "    def __init__(self, config=my_config) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥\n",
    "        self.config = config\n",
    "        self.seq_len = self.config.seq_len\n",
    "        self.vocab_size = self.config.vocab_size\n",
    "        self.hidden_size = self.config.hidden_size\n",
    "        self.emb_size = self.config.embedding_size\n",
    "        self.n_layers = self.config.n_layers\n",
    "        self.device = self.config.device\n",
    "        self.bidirectional = bool(self.config.bidirectional)\n",
    "\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(self.emb_size, self.hidden_size, batch_first=True)\n",
    "        self.bidirect_factor = 2 if self.bidirectional == 1 else 1\n",
    "        self.attn = BahdanauAttention(self.hidden_size)\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, 128), nn.Dropout(), nn.Tanh(), nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def model_description(self):\n",
    "        direction = \"bidirect\" if self.bidirectional else \"onedirect\"\n",
    "        return f\"rnn_{direction}_{self.n_layers}\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x)\n",
    "        outputs, (h_n, _) = self.lstm(embeddings)\n",
    "        # att_hidden, att_weights = self.attn(outputs, h_n[-1].squeeze(0))\n",
    "        att_hidden, att_weights = self.attn(outputs, h_n[-1])\n",
    "        out = self.clf(att_hidden)\n",
    "        return out, att_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e73991e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMBahdanauAttention(config=my_config)\n",
    "model = model.to(my_config.device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "LR_BAN = 1e-4\n",
    "WEIGHT_DECAY_BAN = 3e-4\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=LR_BAN, weight_decay=WEIGHT_DECAY_BAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4169c4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 26 12:53:49 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080        Off |   00000000:01:00.0  On |                  N/A |\n",
      "| 53%   47C    P0            113W /  340W |    1273MiB /  10240MiB |     17%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2081      G   /usr/lib/xorg/Xorg                      311MiB |\n",
      "|    0   N/A  N/A            2311      G   /usr/bin/gnome-shell                     84MiB |\n",
      "|    0   N/A  N/A            2968      G   ...Mattermost/mattermost-desktop         37MiB |\n",
      "|    0   N/A  N/A            3224      G   /opt/zoom/zoom                           44MiB |\n",
      "|    0   N/A  N/A            3232      G   ...-0e3d-4499-9e55-751f7f155f73}          3MiB |\n",
      "|    0   N/A  N/A            4156      G   ...144 --variations-seed-version         81MiB |\n",
      "|    0   N/A  N/A           18809      G   /proc/self/exe                          199MiB |\n",
      "|    0   N/A  N/A           19459      C   ...ect/NLP-BERT/.venv/bin/python        320MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a834cc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–Ω–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...\n",
      "------------- Epoch 1 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce661636acd34be7b574d05ee4a083f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4b1250fc8947b4b9e66ba8aa6538f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.379  Accuracy:  0.822  Precision:  0.824  Recall:  0.904  F1-score:  0.854  \n",
      "Valid stage: loss:  0.231  Accuracy:  0.914  Precision:  0.932  Recall:  0.920  F1-score:  0.925  \n",
      "Time: 9.281614542007446\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 2 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2121c1060984b3ab8314ca3333a00fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed13f01b96e4228a2ac0813931c095b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.214  Accuracy:  0.921  Precision:  0.940  Recall:  0.924  F1-score:  0.931  \n",
      "Valid stage: loss:  0.210  Accuracy:  0.925  Precision:  0.942  Recall:  0.928  F1-score:  0.934  \n",
      "Time: 9.374075889587402\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 3 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3876a9697674d1cada818cc78b0ba43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edafae1100694c6dad760ba250d34dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.199  Accuracy:  0.926  Precision:  0.944  Recall:  0.929  F1-score:  0.936  \n",
      "Valid stage: loss:  0.201  Accuracy:  0.927  Precision:  0.946  Recall:  0.927  F1-score:  0.935  \n",
      "Time: 9.068009376525879\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 4 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba25fda9a694ed6a8428c66cce67324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95cb2959c4d444da4d489e8fcf16883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.190  Accuracy:  0.928  Precision:  0.947  Recall:  0.931  F1-score:  0.938  \n",
      "Valid stage: loss:  0.194  Accuracy:  0.930  Precision:  0.945  Recall:  0.936  F1-score:  0.939  \n",
      "Time: 8.940185070037842\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 5 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a53b1c8db54fb48aa398c5f1e4ed55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [Train]:   0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5eb3ae7dff4047bd02d70a92a92987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [Test]:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.184  Accuracy:  0.931  Precision:  0.948  Recall:  0.933  F1-score:  0.940  \n",
      "Valid stage: loss:  0.191  Accuracy:  0.930  Precision:  0.942  Recall:  0.938  F1-score:  0.939  \n",
      "Time: 8.944113492965698\n",
      "-----------------------------------\n",
      "\n",
      "Total time =  45.6 —Å–µ–∫\n",
      "üèÉ View run LSTM+BahdanauAtt_BS = 64_lr_0.0001 at: http://localhost:5000/#/experiments/590357008120533451/runs/70a33dc53c7a48d486c3a9ecfae6fbfd\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/590357008120533451\n"
     ]
    }
   ],
   "source": [
    "logs, total_time, run = fit_with_mlflow(\n",
    "    model=model,\n",
    "    model_name=\"LSTM+BahdanauAtt\",\n",
    "    epochs=5,\n",
    "    criterion=criterion,\n",
    "    optimizer=optim,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    device=my_config.device,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR_BAN,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
