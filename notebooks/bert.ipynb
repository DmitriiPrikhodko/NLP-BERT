{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a4cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "# импортируем трансформеры\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import warnings\n",
    "\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy,\n",
    "    BinaryPrecision,\n",
    "    BinaryRecall,\n",
    "    BinaryF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassConfusionMatrix,\n",
    "    MulticlassRecall,\n",
    "    MulticlassF1Score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32a9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "from tqdm.auto import tqdm\n",
    "import mlflow\n",
    "from time import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af111ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# GENERATOR = (\n",
    "#     torch.Generator(device=DEVICE) if torch.cuda.is_available() else torch.Generator()\n",
    "# )\n",
    "GENERATOR = torch.Generator()\n",
    "\n",
    "use_mlflow = True\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "CURR_DIR = os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "252fa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0958053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(CURR_DIR, \"data\", \"healthcare_facilities_reviews.jsonl\")) as f:\n",
    "#     df = pd.read_json(f)\n",
    "df = pd.read_json(\n",
    "    os.path.join(CURR_DIR, \"..\", \"data\", \"healthcare_facilities_reviews.jsonl\"),\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f535ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Поликлиники стоматологические</td>\n",
       "      <td>Классный мастер</td>\n",
       "      <td>Огромное спасибо за чудесное удаление двух зуб...</td>\n",
       "      <td>positive</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=2727539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Поликлиники стоматологические</td>\n",
       "      <td>Замечательный врач</td>\n",
       "      <td>Хочу выразить особую благодарность замечательн...</td>\n",
       "      <td>positive</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=2302877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Поликлиники стоматологические</td>\n",
       "      <td>Благодарность работникам рентгена</td>\n",
       "      <td>Добрый вечер! Хотелось бы поблагодарить сотруд...</td>\n",
       "      <td>positive</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=2815031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Поликлиники стоматологические</td>\n",
       "      <td>Доктор Рабинович</td>\n",
       "      <td>Женщины советского образца в регистратуре не и...</td>\n",
       "      <td>negative</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=3443161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Поликлиники стоматологические</td>\n",
       "      <td>Есть кому сказать спасибо</td>\n",
       "      <td>У меня с детства очень плохие зубы (тонкая и х...</td>\n",
       "      <td>positive</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=2592430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                       category  \\\n",
       "0          0  Поликлиники стоматологические   \n",
       "1          1  Поликлиники стоматологические   \n",
       "2          2  Поликлиники стоматологические   \n",
       "3          3  Поликлиники стоматологические   \n",
       "4          4  Поликлиники стоматологические   \n",
       "\n",
       "                               title  \\\n",
       "0                    Классный мастер   \n",
       "1                 Замечательный врач   \n",
       "2  Благодарность работникам рентгена   \n",
       "3                   Доктор Рабинович   \n",
       "4          Есть кому сказать спасибо   \n",
       "\n",
       "                                             content sentiment  \\\n",
       "0  Огромное спасибо за чудесное удаление двух зуб...  positive   \n",
       "1  Хочу выразить особую благодарность замечательн...  positive   \n",
       "2  Добрый вечер! Хотелось бы поблагодарить сотруд...  positive   \n",
       "3  Женщины советского образца в регистратуре не и...  negative   \n",
       "4  У меня с детства очень плохие зубы (тонкая и х...  positive   \n",
       "\n",
       "                                          source_url  \n",
       "0  http://www.spr.ru/forum_vyvod.php?id_tema=2727539  \n",
       "1  http://www.spr.ru/forum_vyvod.php?id_tema=2302877  \n",
       "2  http://www.spr.ru/forum_vyvod.php?id_tema=2815031  \n",
       "3  http://www.spr.ru/forum_vyvod.php?id_tema=3443161  \n",
       "4  http://www.spr.ru/forum_vyvod.php?id_tema=2592430  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a93638d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d75990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"sentiment\"].copy().apply(lambda x: 1 if x == \"positive\" else 0)\n",
    "df[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287c417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70597, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Огромное спасибо за чудесное удаление двух зуб...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хочу выразить особую благодарность замечательн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Добрый вечер! Хотелось бы поблагодарить сотруд...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Женщины советского образца в регистратуре не и...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>У меня с детства очень плохие зубы (тонкая и х...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  labels\n",
       "0  Огромное спасибо за чудесное удаление двух зуб...       1\n",
       "1  Хочу выразить особую благодарность замечательн...       1\n",
       "2  Добрый вечер! Хотелось бы поблагодарить сотруд...       1\n",
       "3  Женщины советского образца в регистратуре не и...       0\n",
       "4  У меня с детства очень плохие зубы (тонкая и х...       1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[:, [\"content\", \"labels\"]].copy()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "699647bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "# model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c286e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_posts = (\n",
    "    data[\"content\"]\n",
    "    .apply(lambda x: tokenizer(x, max_length=64, truncation=True, padding=\"max_length\"))\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "092be610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyBertCLSInputs(torch.utils.data.Dataset):\n",
    "    def __init__(self, encoded_text, y_true):\n",
    "        super().__init__()\n",
    "        self.inputs = encoded_text\n",
    "        self.labels = y_true\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.inputs[idx])\n",
    "        return (\n",
    "            torch.tensor(self.inputs[idx][\"input_ids\"]).long(),\n",
    "            torch.tensor(self.inputs[idx][\"attention_mask\"]).long(),\n",
    "            torch.tensor(self.labels[idx]).long(),  # добавили для классификации\n",
    "        )\n",
    "\n",
    "\n",
    "dataset = TinyBertCLSInputs(encoded_text=encoded_posts, y_true=data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d2dd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "143859ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "train_idx, valid_idx = train_test_split(range(len(labels)), test_size=0.15)\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "valid_ds = Subset(dataset, valid_idx)\n",
    "\n",
    "train_loader_2 = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "valid_loader_2 = DataLoader(\n",
    "    valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d0c441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPersonalTinyBert(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # и снова грузим\n",
    "        self.bert = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "        # заморозим параметры\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        # делаем свой слой для классификации\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(312, 256),  # начинаем с длины embedding, которые делает модель\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 64),  # это добавил для души))\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),  # заканчиваем кол-вом классов\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        vector = bert_out.last_hidden_state[:, 0, :]\n",
    "        classes = self.linear(vector)\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e6925c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyPersonalTinyBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(2048, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=312, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyPersonalTinyBert()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73c29225",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "LR = 2e-4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfdfd0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_metrics(outputs, labels, device, num_classes=2):\n",
    "    acc = BinaryAccuracy().to(device)\n",
    "    prec = BinaryPrecision().to(device)\n",
    "    rec = BinaryRecall().to(device)\n",
    "    f1 = BinaryF1Score().to(device)\n",
    "\n",
    "    preds = outputs.squeeze().float()\n",
    "    labels = labels.squeeze().float()\n",
    "    return (\n",
    "        acc(preds, labels).item(),\n",
    "        prec(preds, labels).item(),\n",
    "        rec(preds, labels).item(),\n",
    "        f1(preds, labels).item(),\n",
    "    )\n",
    "\n",
    "\n",
    "def fit_model(\n",
    "    epochs: int,\n",
    "    model: nn.Module,\n",
    "    model_name: str,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    metrics_func,\n",
    "    use_mlflow=False,\n",
    "    num_classes=2,\n",
    "):\n",
    "\n",
    "    log = dict()\n",
    "    log[\"train_loss\"] = []\n",
    "    log[\"valid_loss\"] = []\n",
    "    log[\"train_accuracy\"] = []\n",
    "    log[\"valid_accuracy\"] = []\n",
    "    log[\"train_precision\"] = []\n",
    "    log[\"valid_precision\"] = []\n",
    "    log[\"train_recall\"] = []\n",
    "    log[\"valid_recall\"] = []\n",
    "    log[\"train_f1\"] = []\n",
    "    log[\"valid_f1\"] = []\n",
    "\n",
    "    time_start = time()\n",
    "\n",
    "    start_epoch = len(log[\"train_loss\"])\n",
    "\n",
    "    ### Создаем папку для записи весов\n",
    "    # -----------------------------------------------------------------\n",
    "    # Создаём корневую папку weights, если её нет\n",
    "    folder_path = f\"weights/\"\n",
    "    model_folder_path = os.path.join(folder_path, f\"{model_name}\")\n",
    "\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "\n",
    "    # Список номеров run_*\n",
    "    run_nums = []\n",
    "\n",
    "    # Ищем все подпапки с именем run_число\n",
    "    for item_name in os.listdir(model_folder_path):\n",
    "        full_path = os.path.join(model_folder_path, item_name)\n",
    "        if os.path.isdir(full_path):\n",
    "            match = re.search(r\"run_(\\d+)\", item_name)\n",
    "            if match:\n",
    "                run_nums.append(int(match.group(1)))\n",
    "\n",
    "    # Определяем следующий номер\n",
    "    run = max(run_nums) + 1 if run_nums else 1\n",
    "\n",
    "    # Создаём новую папку\n",
    "    new_folder = os.path.join(model_folder_path, f\"run_{run}\")\n",
    "    os.makedirs(new_folder, exist_ok=True)\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    ### Цикл обучения\n",
    "    # -----------------------------------------------------------------\n",
    "    for epoch in range(start_epoch + 1, start_epoch + epochs + 1):\n",
    "\n",
    "        curr_run_path = os.path.join(folder_path, model_name, f\"run_{run}\")\n",
    "\n",
    "        epoch_time_start = time()\n",
    "\n",
    "        print(f'{\"-\"*13} Epoch {epoch} {\"-\"*13}')\n",
    "\n",
    "        ### Обучение\n",
    "\n",
    "        batch_acc = []\n",
    "        batch_prec = []\n",
    "        batch_recall = []\n",
    "        batch_loss = []\n",
    "        batch_f1 = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # Прогресс бар\n",
    "\n",
    "        train_pbar = tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=True\n",
    "        )\n",
    "\n",
    "        for inputs, masks, labels in train_pbar:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Функции потерь\n",
    "\n",
    "            outputs = model(inputs, masks)\n",
    "\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).to(outputs.dtype))  # .long())\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            # Метрики\n",
    "            acc, prec, rec, f1 = metrics_func(\n",
    "                outputs, labels, device=device, num_classes=num_classes\n",
    "            )\n",
    "\n",
    "            batch_acc.append(acc)\n",
    "            batch_prec.append(prec)\n",
    "            batch_recall.append(rec)\n",
    "            batch_f1.append(f1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_pbar.set_postfix(\n",
    "            {\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1-score\": f1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        log[\"train_loss\"].append(np.mean(batch_loss))\n",
    "        log[\"train_accuracy\"].append(np.mean(batch_acc))\n",
    "        log[\"train_precision\"].append(np.mean(batch_prec))\n",
    "        log[\"train_recall\"].append(np.mean(batch_recall))\n",
    "        log[\"train_f1\"].append(np.mean(batch_f1))\n",
    "\n",
    "        ### Валидация\n",
    "\n",
    "        batch_acc = []\n",
    "        batch_prec = []\n",
    "        batch_recall = []\n",
    "        batch_loss = []\n",
    "        batch_f1 = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        valid_pbar = tqdm(\n",
    "            valid_loader, desc=f\"Epoch {epoch}/{epochs} [Test]\", leave=True\n",
    "        )\n",
    "        for inputs, masks, labels in valid_pbar:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs, masks)\n",
    "\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).to(outputs.dtype))  # .long())\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            # Метрики\n",
    "            acc, prec, rec, f1 = metrics_func(\n",
    "                outputs, labels, device=device, num_classes=num_classes\n",
    "            )\n",
    "\n",
    "            batch_acc.append(acc)\n",
    "            batch_prec.append(prec)\n",
    "            batch_recall.append(rec)\n",
    "            batch_f1.append(f1)\n",
    "\n",
    "        valid_pbar.set_postfix(\n",
    "            {\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1-score\": f1,\n",
    "            }\n",
    "        )\n",
    "        ### Метрики и логирование\n",
    "\n",
    "        log[\"valid_loss\"].append(np.mean(batch_loss))\n",
    "        log[\"valid_accuracy\"].append(np.mean(batch_acc))\n",
    "        log[\"valid_precision\"].append(np.mean(batch_prec))\n",
    "        log[\"valid_recall\"].append(np.mean(batch_recall))\n",
    "        log[\"valid_f1\"].append(np.mean(batch_f1))\n",
    "\n",
    "        # [MLflow] Логируем метрики\n",
    "        if use_mlflow:\n",
    "            # epoch – номер шага (можно указывать step=epoch)\n",
    "            for c in log.keys():\n",
    "                mlflow.log_metric(c, log[c][-1], step=epoch)\n",
    "\n",
    "        epoch_time = time() - epoch_time_start\n",
    "\n",
    "        ### Выводим результаты эпохи\n",
    "        # Train stage\n",
    "        print(\n",
    "            f\"Train stage: \"\n",
    "            f\"loss: {log['train_loss'][-1]:>6.3f}  \"\n",
    "            f\"Accuracy: {log['train_accuracy'][-1]:>6.3f}  \"\n",
    "            f\"Precision: {log['train_precision'][-1]:>6.3f}  \"\n",
    "            f\"Recall: {log['train_recall'][-1]:>6.3f}  \"\n",
    "            f\"F1-score: {log['train_f1'][-1]:>6.3f}  \"\n",
    "        )\n",
    "\n",
    "        # Valid stage\n",
    "        print(\n",
    "            f\"Valid stage: \"\n",
    "            f\"loss: {log['valid_loss'][-1]:>6.3f}  \"\n",
    "            f\"Accuracy: {log['valid_accuracy'][-1]:>6.3f}  \"\n",
    "            f\"Precision: {log['valid_precision'][-1]:>6.3f}  \"\n",
    "            f\"Recall: {log['valid_recall'][-1]:>6.3f}  \"\n",
    "            f\"F1-score: {log['valid_f1'][-1]:>6.3f}  \"\n",
    "        )\n",
    "        print(f\"Time: {epoch_time}\")\n",
    "\n",
    "        print(f'{\"-\"*35}\\n')\n",
    "        torch.save(\n",
    "            model.state_dict(), os.path.join(curr_run_path, f\"weight_epoch_{epoch}.pth\")\n",
    "        )\n",
    "\n",
    "    total_training_time = time() - time_start\n",
    "    print(f\"Total time = {total_training_time:>5.1f} сек\")\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    return log, total_training_time, run\n",
    "\n",
    "\n",
    "def fit_with_mlflow(\n",
    "    model,\n",
    "    model_name,\n",
    "    epochs,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    batch_size,\n",
    "    lr,\n",
    "    metrics_func,\n",
    "    num_classes=2,\n",
    "):\n",
    "    mlflow.set_experiment(\n",
    "        f\"{model_name} experiment\"\n",
    "    )  # установить (или создать) эксперимент\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_BS = {batch_size}_lr_{lr}\"):\n",
    "        # Логируем гиперпараметры из config\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"device\", device)\n",
    "        mlflow.log_param(\"optimizer\", optimizer)\n",
    "        mlflow.log_param(\"criterion\", criterion)\n",
    "\n",
    "        # mlflow.pytorch.autolog(\n",
    "        #     checkpoint=True,\n",
    "        #     checkpoint_save_best_only=False,\n",
    "        #     checkpoint_save_weights_only=False,\n",
    "        #     checkpoint_save_freq=\"epoch\",\n",
    "        # )\n",
    "        # mlflow.log_param(\"augmentation\", (\"Yes\" if augmentation else \"No\"))\n",
    "        print(\"начало обучения...\")\n",
    "        # Запускаем обучение\n",
    "        logs, tot_time, run = fit_model(\n",
    "            model=model,\n",
    "            model_name=model_name,\n",
    "            epochs=epochs,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            train_loader=train_loader,\n",
    "            valid_loader=valid_loader,\n",
    "            device=device,\n",
    "            use_mlflow=True,\n",
    "            metrics_func=metrics_func,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "        mlflow.log_param(\"Total time\", tot_time)\n",
    "\n",
    "        # Сохраняем модель в MLflow (опционально)\n",
    "        # mlflow.pytorch.log_model(base_cnn, \"model\")\n",
    "\n",
    "    # После выхода из `with` Run автоматически завершается\n",
    "    return logs, tot_time, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26052216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начало обучения...\n",
      "------------- Epoch 1 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 469/469 [00:08<00:00, 58.43it/s]\n",
      "Epoch 1/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 63.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.373  Accuracy:  0.823  Precision:  0.860  Recall:  0.836  F1-score:  0.837  \n",
      "Valid stage: loss:  0.306  Accuracy:  0.869  Precision:  0.910  Recall:  0.864  F1-score:  0.885  \n",
      "Time: 10.61057996749878\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 2 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 469/469 [00:08<00:00, 58.54it/s]\n",
      "Epoch 2/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 66.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.319  Accuracy:  0.861  Precision:  0.892  Recall:  0.868  F1-score:  0.879  \n",
      "Valid stage: loss:  0.297  Accuracy:  0.873  Precision:  0.911  Recall:  0.871  F1-score:  0.890  \n",
      "Time: 10.545008420944214\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 3 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 469/469 [00:08<00:00, 58.09it/s]\n",
      "Epoch 3/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 63.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.310  Accuracy:  0.865  Precision:  0.892  Recall:  0.876  F1-score:  0.883  \n",
      "Valid stage: loss:  0.290  Accuracy:  0.879  Precision:  0.909  Recall:  0.883  F1-score:  0.895  \n",
      "Time: 10.654560327529907\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 4 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 469/469 [00:07<00:00, 58.87it/s]\n",
      "Epoch 4/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 64.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.304  Accuracy:  0.869  Precision:  0.896  Recall:  0.879  F1-score:  0.886  \n",
      "Valid stage: loss:  0.285  Accuracy:  0.879  Precision:  0.908  Recall:  0.885  F1-score:  0.896  \n",
      "Time: 10.54303503036499\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 5 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 469/469 [00:07<00:00, 58.92it/s]\n",
      "Epoch 5/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 64.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.298  Accuracy:  0.872  Precision:  0.898  Recall:  0.882  F1-score:  0.889  \n",
      "Valid stage: loss:  0.281  Accuracy:  0.882  Precision:  0.913  Recall:  0.886  F1-score:  0.899  \n",
      "Time: 10.530460834503174\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 6 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 469/469 [00:07<00:00, 59.60it/s]\n",
      "Epoch 6/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 67.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.294  Accuracy:  0.873  Precision:  0.897  Recall:  0.885  F1-score:  0.890  \n",
      "Valid stage: loss:  0.276  Accuracy:  0.885  Precision:  0.905  Recall:  0.899  F1-score:  0.901  \n",
      "Time: 10.390114068984985\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 7 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 469/469 [00:07<00:00, 58.96it/s]\n",
      "Epoch 7/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 64.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.291  Accuracy:  0.877  Precision:  0.901  Recall:  0.888  F1-score:  0.893  \n",
      "Valid stage: loss:  0.274  Accuracy:  0.884  Precision:  0.909  Recall:  0.893  F1-score:  0.901  \n",
      "Time: 10.52360486984253\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 8 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 469/469 [00:08<00:00, 58.53it/s]\n",
      "Epoch 8/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 65.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.290  Accuracy:  0.875  Precision:  0.899  Recall:  0.888  F1-score:  0.892  \n",
      "Valid stage: loss:  0.272  Accuracy:  0.886  Precision:  0.911  Recall:  0.893  F1-score:  0.902  \n",
      "Time: 10.575334310531616\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 9 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 469/469 [00:07<00:00, 60.25it/s]\n",
      "Epoch 9/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 65.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.285  Accuracy:  0.878  Precision:  0.902  Recall:  0.889  F1-score:  0.895  \n",
      "Valid stage: loss:  0.268  Accuracy:  0.889  Precision:  0.911  Recall:  0.900  F1-score:  0.905  \n",
      "Time: 10.344475030899048\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 10 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 469/469 [00:08<00:00, 58.13it/s]\n",
      "Epoch 10/10 [Test]: 100%|██████████| 83/83 [00:01<00:00, 64.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.282  Accuracy:  0.879  Precision:  0.902  Recall:  0.891  F1-score:  0.896  \n",
      "Valid stage: loss:  0.268  Accuracy:  0.889  Precision:  0.911  Recall:  0.900  F1-score:  0.905  \n",
      "Time: 10.638150930404663\n",
      "-----------------------------------\n",
      "\n",
      "Total time = 106.3 сек\n",
      "🏃 View run rubert-tiny2 + classifier_BS = 128_lr_0.0002 at: http://localhost:5000/#/experiments/795024553813846834/runs/80d18be25eb840d1aae25480a3699ebf\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/795024553813846834\n"
     ]
    }
   ],
   "source": [
    "logs, run_time, run = fit_with_mlflow(\n",
    "    model=model,\n",
    "    model_name=\"rubert-tiny2 + classifier\",\n",
    "    epochs=10,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    train_loader=train_loader_2,\n",
    "    valid_loader=valid_loader_2,\n",
    "    device=DEVICE,\n",
    "    batch_size=128,\n",
    "    lr=LR,\n",
    "    metrics_func=binary_metrics,\n",
    "    num_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a8269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
