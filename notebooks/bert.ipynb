{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a4cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "# –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import warnings\n",
    "\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy,\n",
    "    BinaryPrecision,\n",
    "    BinaryRecall,\n",
    "    BinaryF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassConfusionMatrix,\n",
    "    MulticlassRecall,\n",
    "    MulticlassF1Score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32a9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "from tqdm.auto import tqdm\n",
    "import mlflow\n",
    "from time import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af111ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# GENERATOR = (\n",
    "#     torch.Generator(device=DEVICE) if torch.cuda.is_available() else torch.Generator()\n",
    "# )\n",
    "GENERATOR = torch.Generator()\n",
    "\n",
    "use_mlflow = True\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "CURR_DIR = os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "252fa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0958053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(CURR_DIR, \"data\", \"healthcare_facilities_reviews.jsonl\")) as f:\n",
    "#     df = pd.read_json(f)\n",
    "df = pd.read_json(\n",
    "    os.path.join(CURR_DIR, \"..\", \"data\", \"healthcare_facilities_reviews.jsonl\"),\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f535ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>–ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ</td>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω—ã–π –º–∞—Å—Ç–µ—Ä</td>\n",
       "      <td>–û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –∑–∞ —á—É–¥–µ—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥–≤—É—Ö –∑—É–±...</td>\n",
       "      <td>positive</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=2727539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ</td>\n",
       "      <td>–ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π –≤—Ä–∞—á</td>\n",
       "      <td>–•–æ—á—É –≤—ã—Ä–∞–∑–∏—Ç—å –æ—Å–æ–±—É—é –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω...</td>\n",
       "      <td>positive</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=2302877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>–ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ</td>\n",
       "      <td>–ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç–Ω–∏–∫–∞–º —Ä–µ–Ω—Ç–≥–µ–Ω–∞</td>\n",
       "      <td>–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä! –•–æ—Ç–µ–ª–æ—Å—å –±—ã –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å —Å–æ—Ç—Ä—É–¥...</td>\n",
       "      <td>positive</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=2815031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>–ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ</td>\n",
       "      <td>–î–æ–∫—Ç–æ—Ä –†–∞–±–∏–Ω–æ–≤–∏—á</td>\n",
       "      <td>–ñ–µ–Ω—â–∏–Ω—ã —Å–æ–≤–µ—Ç—Å–∫–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞ –≤ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–µ –Ω–µ –∏...</td>\n",
       "      <td>negative</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=3443161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>–ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ</td>\n",
       "      <td>–ï—Å—Ç—å –∫–æ–º—É —Å–∫–∞–∑–∞—Ç—å —Å–ø–∞—Å–∏–±–æ</td>\n",
       "      <td>–£ –º–µ–Ω—è —Å –¥–µ—Ç—Å—Ç–≤–∞ –æ—á–µ–Ω—å –ø–ª–æ—Ö–∏–µ –∑—É–±—ã (—Ç–æ–Ω–∫–∞—è –∏ —Ö...</td>\n",
       "      <td>positive</td>\n",
       "      <td>http://www.spr.ru/forum_vyvod.php?id_tema=2592430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                       category  \\\n",
       "0          0  –ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ   \n",
       "1          1  –ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ   \n",
       "2          2  –ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ   \n",
       "3          3  –ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ   \n",
       "4          4  –ü–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ   \n",
       "\n",
       "                               title  \\\n",
       "0                    –ö–ª–∞—Å—Å–Ω—ã–π –º–∞—Å—Ç–µ—Ä   \n",
       "1                 –ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π –≤—Ä–∞—á   \n",
       "2  –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç–Ω–∏–∫–∞–º —Ä–µ–Ω—Ç–≥–µ–Ω–∞   \n",
       "3                   –î–æ–∫—Ç–æ—Ä –†–∞–±–∏–Ω–æ–≤–∏—á   \n",
       "4          –ï—Å—Ç—å –∫–æ–º—É —Å–∫–∞–∑–∞—Ç—å —Å–ø–∞—Å–∏–±–æ   \n",
       "\n",
       "                                             content sentiment  \\\n",
       "0  –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –∑–∞ —á—É–¥–µ—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥–≤—É—Ö –∑—É–±...  positive   \n",
       "1  –•–æ—á—É –≤—ã—Ä–∞–∑–∏—Ç—å –æ—Å–æ–±—É—é –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω...  positive   \n",
       "2  –î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä! –•–æ—Ç–µ–ª–æ—Å—å –±—ã –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å —Å–æ—Ç—Ä—É–¥...  positive   \n",
       "3  –ñ–µ–Ω—â–∏–Ω—ã —Å–æ–≤–µ—Ç—Å–∫–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞ –≤ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–µ –Ω–µ –∏...  negative   \n",
       "4  –£ –º–µ–Ω—è —Å –¥–µ—Ç—Å—Ç–≤–∞ –æ—á–µ–Ω—å –ø–ª–æ—Ö–∏–µ –∑—É–±—ã (—Ç–æ–Ω–∫–∞—è –∏ —Ö...  positive   \n",
       "\n",
       "                                          source_url  \n",
       "0  http://www.spr.ru/forum_vyvod.php?id_tema=2727539  \n",
       "1  http://www.spr.ru/forum_vyvod.php?id_tema=2302877  \n",
       "2  http://www.spr.ru/forum_vyvod.php?id_tema=2815031  \n",
       "3  http://www.spr.ru/forum_vyvod.php?id_tema=3443161  \n",
       "4  http://www.spr.ru/forum_vyvod.php?id_tema=2592430  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a93638d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d75990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"sentiment\"].copy().apply(lambda x: 1 if x == \"positive\" else 0)\n",
    "df[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287c417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70597, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –∑–∞ —á—É–¥–µ—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥–≤—É—Ö –∑—É–±...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–•–æ—á—É –≤—ã—Ä–∞–∑–∏—Ç—å –æ—Å–æ–±—É—é –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä! –•–æ—Ç–µ–ª–æ—Å—å –±—ã –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å —Å–æ—Ç—Ä—É–¥...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ñ–µ–Ω—â–∏–Ω—ã —Å–æ–≤–µ—Ç—Å–∫–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞ –≤ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–µ –Ω–µ –∏...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–£ –º–µ–Ω—è —Å –¥–µ—Ç—Å—Ç–≤–∞ –æ—á–µ–Ω—å –ø–ª–æ—Ö–∏–µ –∑—É–±—ã (—Ç–æ–Ω–∫–∞—è –∏ —Ö...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  labels\n",
       "0  –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –∑–∞ —á—É–¥–µ—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥–≤—É—Ö –∑—É–±...       1\n",
       "1  –•–æ—á—É –≤—ã—Ä–∞–∑–∏—Ç—å –æ—Å–æ–±—É—é –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω...       1\n",
       "2  –î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä! –•–æ—Ç–µ–ª–æ—Å—å –±—ã –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å —Å–æ—Ç—Ä—É–¥...       1\n",
       "3  –ñ–µ–Ω—â–∏–Ω—ã —Å–æ–≤–µ—Ç—Å–∫–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞ –≤ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–µ –Ω–µ –∏...       0\n",
       "4  –£ –º–µ–Ω—è —Å –¥–µ—Ç—Å—Ç–≤–∞ –æ—á–µ–Ω—å –ø–ª–æ—Ö–∏–µ –∑—É–±—ã (—Ç–æ–Ω–∫–∞—è –∏ —Ö...       1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[:, [\"content\", \"labels\"]].copy()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "699647bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "# model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c286e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_posts = (\n",
    "    data[\"content\"]\n",
    "    .apply(lambda x: tokenizer(x, max_length=64, truncation=True, padding=\"max_length\"))\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "092be610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyBertCLSInputs(torch.utils.data.Dataset):\n",
    "    def __init__(self, encoded_text, y_true):\n",
    "        super().__init__()\n",
    "        self.inputs = encoded_text\n",
    "        self.labels = y_true\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.inputs[idx])\n",
    "        return (\n",
    "            torch.tensor(self.inputs[idx][\"input_ids\"]).long(),\n",
    "            torch.tensor(self.inputs[idx][\"attention_mask\"]).long(),\n",
    "            torch.tensor(self.labels[idx]).long(),  # –¥–æ–±–∞–≤–∏–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "        )\n",
    "\n",
    "\n",
    "dataset = TinyBertCLSInputs(encoded_text=encoded_posts, y_true=data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d2dd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "143859ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "train_idx, valid_idx = train_test_split(range(len(labels)), test_size=0.15)\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "valid_ds = Subset(dataset, valid_idx)\n",
    "\n",
    "train_loader_2 = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "valid_loader_2 = DataLoader(\n",
    "    valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d0c441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPersonalTinyBert(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # –∏ —Å–Ω–æ–≤–∞ –≥—Ä—É–∑–∏–º\n",
    "        self.bert = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "        # –∑–∞–º–æ—Ä–æ–∑–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        # –¥–µ–ª–∞–µ–º —Å–≤–æ–π —Å–ª–æ–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(312, 256),  # –Ω–∞—á–∏–Ω–∞–µ–º —Å –¥–ª–∏–Ω—ã embedding, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–ª–∞–µ—Ç –º–æ–¥–µ–ª—å\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 64),  # —ç—Ç–æ –¥–æ–±–∞–≤–∏–ª –¥–ª—è –¥—É—à–∏))\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),  # –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ–º –∫–æ–ª-–≤–æ–º –∫–ª–∞—Å—Å–æ–≤\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        vector = bert_out.last_hidden_state[:, 0, :]\n",
    "        classes = self.linear(vector)\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e6925c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyPersonalTinyBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(2048, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=312, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyPersonalTinyBert()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73c29225",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "LR = 2e-4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfdfd0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_metrics(outputs, labels, device, num_classes=2):\n",
    "    acc = BinaryAccuracy().to(device)\n",
    "    prec = BinaryPrecision().to(device)\n",
    "    rec = BinaryRecall().to(device)\n",
    "    f1 = BinaryF1Score().to(device)\n",
    "\n",
    "    preds = outputs.squeeze().float()\n",
    "    labels = labels.squeeze().float()\n",
    "    return (\n",
    "        acc(preds, labels).item(),\n",
    "        prec(preds, labels).item(),\n",
    "        rec(preds, labels).item(),\n",
    "        f1(preds, labels).item(),\n",
    "    )\n",
    "\n",
    "\n",
    "def fit_model(\n",
    "    epochs: int,\n",
    "    model: nn.Module,\n",
    "    model_name: str,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    metrics_func,\n",
    "    use_mlflow=False,\n",
    "    num_classes=2,\n",
    "):\n",
    "\n",
    "    log = dict()\n",
    "    log[\"train_loss\"] = []\n",
    "    log[\"valid_loss\"] = []\n",
    "    log[\"train_accuracy\"] = []\n",
    "    log[\"valid_accuracy\"] = []\n",
    "    log[\"train_precision\"] = []\n",
    "    log[\"valid_precision\"] = []\n",
    "    log[\"train_recall\"] = []\n",
    "    log[\"valid_recall\"] = []\n",
    "    log[\"train_f1\"] = []\n",
    "    log[\"valid_f1\"] = []\n",
    "\n",
    "    time_start = time()\n",
    "\n",
    "    start_epoch = len(log[\"train_loss\"])\n",
    "\n",
    "    ### –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤–µ—Å–æ–≤\n",
    "    # -----------------------------------------------------------------\n",
    "    # –°–æ–∑–¥–∞—ë–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É weights, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\n",
    "    folder_path = f\"weights/\"\n",
    "    model_folder_path = os.path.join(folder_path, f\"{model_name}\")\n",
    "\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "\n",
    "    # –°–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ run_*\n",
    "    run_nums = []\n",
    "\n",
    "    # –ò—â–µ–º –≤—Å–µ –ø–æ–¥–ø–∞–ø–∫–∏ —Å –∏–º–µ–Ω–µ–º run_—á–∏—Å–ª–æ\n",
    "    for item_name in os.listdir(model_folder_path):\n",
    "        full_path = os.path.join(model_folder_path, item_name)\n",
    "        if os.path.isdir(full_path):\n",
    "            match = re.search(r\"run_(\\d+)\", item_name)\n",
    "            if match:\n",
    "                run_nums.append(int(match.group(1)))\n",
    "\n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–º–µ—Ä\n",
    "    run = max(run_nums) + 1 if run_nums else 1\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –ø–∞–ø–∫—É\n",
    "    new_folder = os.path.join(model_folder_path, f\"run_{run}\")\n",
    "    os.makedirs(new_folder, exist_ok=True)\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    ### –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\n",
    "    # -----------------------------------------------------------------\n",
    "    for epoch in range(start_epoch + 1, start_epoch + epochs + 1):\n",
    "\n",
    "        curr_run_path = os.path.join(folder_path, model_name, f\"run_{run}\")\n",
    "\n",
    "        epoch_time_start = time()\n",
    "\n",
    "        print(f'{\"-\"*13} Epoch {epoch} {\"-\"*13}')\n",
    "\n",
    "        ### –û–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "        batch_acc = []\n",
    "        batch_prec = []\n",
    "        batch_recall = []\n",
    "        batch_loss = []\n",
    "        batch_f1 = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä\n",
    "\n",
    "        train_pbar = tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=True\n",
    "        )\n",
    "\n",
    "        for inputs, masks, labels in train_pbar:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "\n",
    "            outputs = model(inputs, masks)\n",
    "\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).to(outputs.dtype))  # .long())\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "            acc, prec, rec, f1 = metrics_func(\n",
    "                outputs, labels, device=device, num_classes=num_classes\n",
    "            )\n",
    "\n",
    "            batch_acc.append(acc)\n",
    "            batch_prec.append(prec)\n",
    "            batch_recall.append(rec)\n",
    "            batch_f1.append(f1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_pbar.set_postfix(\n",
    "            {\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1-score\": f1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        log[\"train_loss\"].append(np.mean(batch_loss))\n",
    "        log[\"train_accuracy\"].append(np.mean(batch_acc))\n",
    "        log[\"train_precision\"].append(np.mean(batch_prec))\n",
    "        log[\"train_recall\"].append(np.mean(batch_recall))\n",
    "        log[\"train_f1\"].append(np.mean(batch_f1))\n",
    "\n",
    "        ### –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "\n",
    "        batch_acc = []\n",
    "        batch_prec = []\n",
    "        batch_recall = []\n",
    "        batch_loss = []\n",
    "        batch_f1 = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        valid_pbar = tqdm(\n",
    "            valid_loader, desc=f\"Epoch {epoch}/{epochs} [Test]\", leave=True\n",
    "        )\n",
    "        for inputs, masks, labels in valid_pbar:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs, masks)\n",
    "\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).to(outputs.dtype))  # .long())\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "            acc, prec, rec, f1 = metrics_func(\n",
    "                outputs, labels, device=device, num_classes=num_classes\n",
    "            )\n",
    "\n",
    "            batch_acc.append(acc)\n",
    "            batch_prec.append(prec)\n",
    "            batch_recall.append(rec)\n",
    "            batch_f1.append(f1)\n",
    "\n",
    "        valid_pbar.set_postfix(\n",
    "            {\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1-score\": f1,\n",
    "            }\n",
    "        )\n",
    "        ### –ú–µ—Ç—Ä–∏–∫–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "\n",
    "        log[\"valid_loss\"].append(np.mean(batch_loss))\n",
    "        log[\"valid_accuracy\"].append(np.mean(batch_acc))\n",
    "        log[\"valid_precision\"].append(np.mean(batch_prec))\n",
    "        log[\"valid_recall\"].append(np.mean(batch_recall))\n",
    "        log[\"valid_f1\"].append(np.mean(batch_f1))\n",
    "\n",
    "        # [MLflow] –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        if use_mlflow:\n",
    "            # epoch ‚Äì –Ω–æ–º–µ—Ä —à–∞–≥–∞ (–º–æ–∂–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å step=epoch)\n",
    "            for c in log.keys():\n",
    "                mlflow.log_metric(c, log[c][-1], step=epoch)\n",
    "\n",
    "        epoch_time = time() - epoch_time_start\n",
    "\n",
    "        ### –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏\n",
    "        # Train stage\n",
    "        print(\n",
    "            f\"Train stage: \"\n",
    "            f\"loss: {log['train_loss'][-1]:>6.3f}  \"\n",
    "            f\"Accuracy: {log['train_accuracy'][-1]:>6.3f}  \"\n",
    "            f\"Precision: {log['train_precision'][-1]:>6.3f}  \"\n",
    "            f\"Recall: {log['train_recall'][-1]:>6.3f}  \"\n",
    "            f\"F1-score: {log['train_f1'][-1]:>6.3f}  \"\n",
    "        )\n",
    "\n",
    "        # Valid stage\n",
    "        print(\n",
    "            f\"Valid stage: \"\n",
    "            f\"loss: {log['valid_loss'][-1]:>6.3f}  \"\n",
    "            f\"Accuracy: {log['valid_accuracy'][-1]:>6.3f}  \"\n",
    "            f\"Precision: {log['valid_precision'][-1]:>6.3f}  \"\n",
    "            f\"Recall: {log['valid_recall'][-1]:>6.3f}  \"\n",
    "            f\"F1-score: {log['valid_f1'][-1]:>6.3f}  \"\n",
    "        )\n",
    "        print(f\"Time: {epoch_time}\")\n",
    "\n",
    "        print(f'{\"-\"*35}\\n')\n",
    "        torch.save(\n",
    "            model.state_dict(), os.path.join(curr_run_path, f\"weight_epoch_{epoch}.pth\")\n",
    "        )\n",
    "\n",
    "    total_training_time = time() - time_start\n",
    "    print(f\"Total time = {total_training_time:>5.1f} —Å–µ–∫\")\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    return log, total_training_time, run\n",
    "\n",
    "\n",
    "def fit_with_mlflow(\n",
    "    model,\n",
    "    model_name,\n",
    "    epochs,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    batch_size,\n",
    "    lr,\n",
    "    metrics_func,\n",
    "    num_classes=2,\n",
    "):\n",
    "    mlflow.set_experiment(\n",
    "        f\"{model_name} experiment\"\n",
    "    )  # —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å (–∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å) —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_BS = {batch_size}_lr_{lr}\"):\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"device\", device)\n",
    "        mlflow.log_param(\"optimizer\", optimizer)\n",
    "        mlflow.log_param(\"criterion\", criterion)\n",
    "\n",
    "        # mlflow.pytorch.autolog(\n",
    "        #     checkpoint=True,\n",
    "        #     checkpoint_save_best_only=False,\n",
    "        #     checkpoint_save_weights_only=False,\n",
    "        #     checkpoint_save_freq=\"epoch\",\n",
    "        # )\n",
    "        # mlflow.log_param(\"augmentation\", (\"Yes\" if augmentation else \"No\"))\n",
    "        print(\"–Ω–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...\")\n",
    "        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "        logs, tot_time, run = fit_model(\n",
    "            model=model,\n",
    "            model_name=model_name,\n",
    "            epochs=epochs,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            train_loader=train_loader,\n",
    "            valid_loader=valid_loader,\n",
    "            device=device,\n",
    "            use_mlflow=True,\n",
    "            metrics_func=metrics_func,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "        mlflow.log_param(\"Total time\", tot_time)\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ MLflow (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "        # mlflow.pytorch.log_model(base_cnn, \"model\")\n",
    "\n",
    "    # –ü–æ—Å–ª–µ –≤—ã—Ö–æ–¥–∞ –∏–∑ `with` Run –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è\n",
    "    return logs, tot_time, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26052216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–Ω–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...\n",
      "------------- Epoch 1 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:08<00:00, 58.43it/s]\n",
      "Epoch 1/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 63.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.373  Accuracy:  0.823  Precision:  0.860  Recall:  0.836  F1-score:  0.837  \n",
      "Valid stage: loss:  0.306  Accuracy:  0.869  Precision:  0.910  Recall:  0.864  F1-score:  0.885  \n",
      "Time: 10.61057996749878\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 2 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:08<00:00, 58.54it/s]\n",
      "Epoch 2/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 66.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.319  Accuracy:  0.861  Precision:  0.892  Recall:  0.868  F1-score:  0.879  \n",
      "Valid stage: loss:  0.297  Accuracy:  0.873  Precision:  0.911  Recall:  0.871  F1-score:  0.890  \n",
      "Time: 10.545008420944214\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 3 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:08<00:00, 58.09it/s]\n",
      "Epoch 3/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 63.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.310  Accuracy:  0.865  Precision:  0.892  Recall:  0.876  F1-score:  0.883  \n",
      "Valid stage: loss:  0.290  Accuracy:  0.879  Precision:  0.909  Recall:  0.883  F1-score:  0.895  \n",
      "Time: 10.654560327529907\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 4 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 58.87it/s]\n",
      "Epoch 4/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 64.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.304  Accuracy:  0.869  Precision:  0.896  Recall:  0.879  F1-score:  0.886  \n",
      "Valid stage: loss:  0.285  Accuracy:  0.879  Precision:  0.908  Recall:  0.885  F1-score:  0.896  \n",
      "Time: 10.54303503036499\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 5 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 58.92it/s]\n",
      "Epoch 5/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 64.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.298  Accuracy:  0.872  Precision:  0.898  Recall:  0.882  F1-score:  0.889  \n",
      "Valid stage: loss:  0.281  Accuracy:  0.882  Precision:  0.913  Recall:  0.886  F1-score:  0.899  \n",
      "Time: 10.530460834503174\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 6 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 59.60it/s]\n",
      "Epoch 6/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 67.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.294  Accuracy:  0.873  Precision:  0.897  Recall:  0.885  F1-score:  0.890  \n",
      "Valid stage: loss:  0.276  Accuracy:  0.885  Precision:  0.905  Recall:  0.899  F1-score:  0.901  \n",
      "Time: 10.390114068984985\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 7 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 58.96it/s]\n",
      "Epoch 7/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 64.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.291  Accuracy:  0.877  Precision:  0.901  Recall:  0.888  F1-score:  0.893  \n",
      "Valid stage: loss:  0.274  Accuracy:  0.884  Precision:  0.909  Recall:  0.893  F1-score:  0.901  \n",
      "Time: 10.52360486984253\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 8 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:08<00:00, 58.53it/s]\n",
      "Epoch 8/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 65.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.290  Accuracy:  0.875  Precision:  0.899  Recall:  0.888  F1-score:  0.892  \n",
      "Valid stage: loss:  0.272  Accuracy:  0.886  Precision:  0.911  Recall:  0.893  F1-score:  0.902  \n",
      "Time: 10.575334310531616\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 9 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 60.25it/s]\n",
      "Epoch 9/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 65.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.285  Accuracy:  0.878  Precision:  0.902  Recall:  0.889  F1-score:  0.895  \n",
      "Valid stage: loss:  0.268  Accuracy:  0.889  Precision:  0.911  Recall:  0.900  F1-score:  0.905  \n",
      "Time: 10.344475030899048\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 10 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:08<00:00, 58.13it/s]\n",
      "Epoch 10/10 [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:01<00:00, 64.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: loss:  0.282  Accuracy:  0.879  Precision:  0.902  Recall:  0.891  F1-score:  0.896  \n",
      "Valid stage: loss:  0.268  Accuracy:  0.889  Precision:  0.911  Recall:  0.900  F1-score:  0.905  \n",
      "Time: 10.638150930404663\n",
      "-----------------------------------\n",
      "\n",
      "Total time = 106.3 —Å–µ–∫\n",
      "üèÉ View run rubert-tiny2 + classifier_BS = 128_lr_0.0002 at: http://localhost:5000/#/experiments/795024553813846834/runs/80d18be25eb840d1aae25480a3699ebf\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/795024553813846834\n"
     ]
    }
   ],
   "source": [
    "logs, run_time, run = fit_with_mlflow(\n",
    "    model=model,\n",
    "    model_name=\"rubert-tiny2 + classifier\",\n",
    "    epochs=10,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    train_loader=train_loader_2,\n",
    "    valid_loader=valid_loader_2,\n",
    "    device=DEVICE,\n",
    "    batch_size=128,\n",
    "    lr=LR,\n",
    "    metrics_func=binary_metrics,\n",
    "    num_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a8269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
